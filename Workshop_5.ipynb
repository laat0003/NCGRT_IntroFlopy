{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99be5aaf-66e5-4a92-b57a-61513e00bcbd",
   "metadata": {},
   "source": [
    "# Workshop 5\r\n",
    "Hi and welcome to the fifth workshop. In this session we will take a look at a couple of the advanced stress packages because they tend to have input requirements that are somewhat uncommon to the regular stress packages. Specifically, we will focus on the lake package (LAK) and the multi-aquifer well package (MAW) to demonstrate how the different data requirements for these packages are developed and used in Flopy objects. We picked the MAW because of applicability and the LAK because it also introduces cell connectivity data input similar to the GWF-GWF package used for linking multiple models in MF6. Once you have a grasp of the input requirements for these packages the remaining advanced stress packages should not pose a significant obstacle. In addition to the advanced stress package creation, we will introduce some of the inbuilt post-processing capabilities of Flopy and provide applied use examples of how they can be used to good effect\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bfcad-a557-46d3-8ac4-a3bee5ff9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "from flopy.discretization import VertexGrid\n",
    "from flopy.utils import Raster\n",
    "from flopy.utils import GridIntersect\n",
    "from flopy.utils.gridgen import Gridgen\n",
    "gridgen_exe = \"gridgen\"\n",
    "if platform.system() in \"Windows\":\n",
    "    gridgen_exe += \".exe\"\n",
    "gridgen_exe = flopy.which(\"gridgen\")\n",
    "if gridgen_exe is None:\n",
    "    msg = (\n",
    "        \"Warning, gridgen is not in your path. \"\n",
    "        \"When you create the griden object you will need to \"\n",
    "        \"provide a full path to the gridgen binary executable.\"\n",
    "    )\n",
    "    print(msg)\n",
    "else:\n",
    "    print(\"gridgen executable was found at: {}\".format(gridgen_exe))\n",
    "\n",
    "print(f\"Pandas version = {pd.__version__}\")\n",
    "print(f\"Numpy version = {np.__version__}\")\n",
    "print(f\"Flopy version = {flopy.__version__}\")\n",
    "print(f\"Matplotlib version = {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c49bc-0942-4854-a431-ec5bbec1c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws5 = os.path.join('workshop_5') # here we are making a path not creating the folder\n",
    "gis_f = os.path.join(ws5,'GIS') # creating a sub-directory path for our gis input/output\n",
    "model_f = os.path.join(ws5,'model') # creating a sub-directory path for our model input/output\n",
    "plots_f = os.path.join(ws5,'plots') # creating a sub-directory path for our plots\n",
    "for path in [ws5,gis_f,model_f,plots_f]:\n",
    "    if os.path.exists(path): # here we are asking if the path exists on the computer. \n",
    "        shutil.rmtree(path)# if it does exist, delete it and all the files in it\n",
    "        os.mkdir(path) # then remake it\n",
    "    else:\n",
    "        os.mkdir(path) # if it doesn't exist then make the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0dda4-6a6f-4486-a0fd-30afe07358f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import ws5_model1\n",
    "sim, gwf = ws5_model1(ws5,gis_f,model_f,plots_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696597f-60bb-47a5-864a-220cf1da01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f7bb7-78c9-4744-9f08-1ff244944169",
   "metadata": {},
   "source": [
    "# A summary of the budget\r\n",
    "Budget summaries should be checked consistently throughout the model development process as a rule. Recall that you configure the frequency of the summary printed to the list file via the OC package demonstrated in the previous workshop. Here we are going to use a convenient utility function of Flopy to load the list file and then convert the budget summaries into data frames that we can then use for plotting\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee8a08-db6f-4264-81a6-c8a46d4f308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at budget summary\n",
    "lst = flopy.utils.Mf6ListBudget(os.path.join(model_f,\"flow.lst\")) # create a list file object for the current model run\n",
    "\n",
    "df_flux, df_vol = lst.get_dataframes(start_datetime='31-12-2023') # use a method of the listfile object to convert the budget summaries to data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b776ea-b309-4705-9913-5c138ca72acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720af4db-b631-4d81-ae4a-4d7d7825eb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3887b0d8-19c7-40ca-8561-26b8648aedca",
   "metadata": {},
   "source": [
    "Staring at numbers may be tedious for some people who might prefer something visual. So lets create a summary plot of the budget fluxes. We first separate ins and outs using Pandas groupby dataframe method using axis=1, which means we are moving across the columns. What we pass into the groupby method is a lambda function. The lambda function is going to return the string trailing the final underscore in each column name. The groupby method can provide you with lots of information but we are only interested in the groups and their members so the final groups in the expression below will return a dictionary with the group as a key and the list of group members as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d37314-3659-448d-bde1-36dd7aa4d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_flux.groupby(lambda x: x.split(\"_\")[-1], axis=1).groups # splitting by the underscore to get in, out, or discrepancy groups.\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4f3fe-989b-42fa-958d-389b8d0c5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flux_in = df_flux.loc[:, groups[\"IN\"]] # create a dataframe view of the fluxes into the model\n",
    "df_flux_in.columns = df_flux_in.columns.map(lambda x: x.split(\"_\")[0]) # change the columns names here to exclude the \"_IN\"\n",
    "# note use of the map method, which can be loosley translated to \"apply to all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b81a97-f314-4232-8c65-c8c919b228ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for outs\n",
    "df_flux_out = df_flux.loc[:, groups[\"OUT\"]]\n",
    "df_flux_out.columns = df_flux_out.columns.map(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be796575-c254-454b-a9c0-c7c0d60cc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the outs from the ins\n",
    "df_flux_delta = df_flux_in - df_flux_out\n",
    "# change from kL/d to ML/d\n",
    "df_flux_delta = df_flux_delta*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c502c-1f05-447c-8128-2322b8bbb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot a specific stress period using Pandas dataframe plot methods\n",
    "spnum = 12\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax) # note using stress period number here instead of date\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b459f-56dc-4d50-af8c-6641b83134af",
   "metadata": {},
   "source": [
    "Recharge and ET dominate the plot making a comparison of other fluxes difficult. You can solve this by dropping them from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc177b-6625-4333-b7c6-5b86989e937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta = df_flux_delta.drop(columns=[\"RCHA\",\"EVTA\"]) # note these are huge in comparison so we are dropping them for now.\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax)\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a62fe0-a008-4b42-bb29-0fd0790762a2",
   "metadata": {},
   "source": [
    "# Saving the heads for subsequent simulations\r\n",
    "This was demonstrated but not used in the previous workshop. We will be running our model again so letâ€™s save the initial condition heads for use again later\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e333dc9-6c9f-4c89-b0a1-83bd9d972c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "headfile = os.path.join(model_f,\"flow.hds\")\n",
    "hds = flopy.utils.binaryfile.HeadFile(headfile)\n",
    "h = hds.get_data((0,0))\n",
    "np.savetxt(\"iheads_array.txt\",h[0]) # note this is not saved to the model folder because if I choose to rerun the script from scrtach it will be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9675f-b135-4164-9288-c4f66d25051d",
   "metadata": {},
   "source": [
    "# MAW package\r\n",
    "Take a look at the MAW package input file in the MF6io.pdf document. You will notice that in addition to an options section you have to specify three other datasets. This includes package data, connection data and stress period data. In this example we will use a shapefile of bore locations to intersect the model grid and obtain the relevant nodes for each well. A function that we used to assign boundary conditions via intersections will be used. This function works well for lines points and polygons but will cause problems if you have multiple features\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb2ab0-3b52-40ea-a42d-123abf49ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "def get_bnodes(shpfyl): # works with single and multiple line strings\n",
    "    ix = GridIntersect(mg, method=\"vertex\") # build our intersection object we will be applyitng this to a vertex grid only\n",
    "    poly = gpd.read_file(shpfyl).geometry # read in the shapefile\n",
    "    if len(poly)==1: # if the feature only has one entry\n",
    "        return(ix.intersect(poly[0]).cellids) # note this is an array\n",
    "    else: \n",
    "        ls = [] # if the feature has mutiple items i.e. points or multi-line strings\n",
    "        for item in poly: # loop through the different geometries of each item\n",
    "            nums = ix.intersect(item).cellids\n",
    "            ls = [*ls,*nums]\n",
    "        return(np.asarray(ls)) # # this will also be an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4c5bb-4392-49fe-bfc6-b77a61271a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in wells for explicit dewatering simulation\n",
    "mg = gwf.modelgrid\n",
    "wels = os.path.join(gis_f,\"dewatering_wells.shp\")\n",
    "well_nodes = get_bnodes(wels)\n",
    "wel_gdf = gpd.read_file(wels)\n",
    "wel_gdf['node'] = well_nodes\n",
    "wel_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80aba4-d5a5-4691-9f2c-7864bef4d982",
   "metadata": {},
   "source": [
    "Bore and pump depth are included in the shapefile so we will use this to configure our simulated bores. Note the MAW package offers many different options for well simulation behaviour and it is useful to know how you can best utilize the package for your specific simulation. However, in this instance we will adopt the 'THEIM' behaviour option. Each well has a single package data entry but can have multiple connection data entries depending on the different layers intercepted by the screen interval. We only have a three layer model and the wells may or may not reach layer 2. The algorithm below will use the layer elevation data and the bore drill depth to determine the number of connections needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d330d-ab27-4d85-ab3a-f6b373d78e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 0.3 # assume all bores have a radius of 0.3 m\n",
    "condeqn = \"THEIM\" # the string for setting the MAW behaviour option\n",
    "pakdata = [] # initialze some empty lists for package data and connection data\n",
    "condata = []\n",
    "for i in range(len(wel_gdf)): # for each well\n",
    "    welnum = i # assign a unique well number\n",
    "    wel = wel_gdf.loc[i] # get the row entry for the well in the dataframe form the shapefile\n",
    "    bottom = wel[\"Z\"] - wel[\"Bore Depth\"] # Work out the bottom elevation of the well\n",
    "    count = 0 # set a count for the number of connections\n",
    "    node = wel[\"node\"] # this is the node in layer 1 that we got from our function\n",
    "    start = mg.top[node] # set a starting elevation\n",
    "    name = wel[\"Bore\"] # get the well name\n",
    "    for lay in range(3): # nlay =  3 Now loop thorugh each layers bottom elevation for the same node\n",
    "        if mg.botm[lay][node]>bottom: # conditional on the layer elevation\n",
    "            entry2 = (welnum,count,(lay,node),1,1,1,1)\n",
    "            condata.append(entry2)\n",
    "            count+=1\n",
    "    entry = (welnum,rad,bottom,start,condeqn,count,name)\n",
    "    pakdata.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2268b-a7dd-40b4-82aa-30f6adad34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pakdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabded8a-fd7f-46bb-8192-d1769c2ba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "condata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff8dd-d020-4d6a-a1fb-dd9565686a80",
   "metadata": {},
   "source": [
    "So it looks like some of the wells are only in the first layer while others are in the second layer. Once we have the package and connection data we can configure the stress period data. The rates needed from the shapefile are in the column named Dewateri_2. The \"settings =\" line is noteworthy. Each entry for single well is a list of lists, where each nested list has the well number as the first entry then a keyword followed by settings specific to that keyword. For example the keyword \"status\" requires another string as the setting, in this case \"active\". The keyword \"rate_scaling\" requires two float values (d and l). If you look in the MF6io.pdf document you can see what each keyword requires as its settings. Also very important, is making sure you comprehend how advanced stress packages turn on and off. This differs slightly from other stress packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17111b8f-5703-4fb2-9530-152b19a08d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then finally we also need period data configured for each well\n",
    "maw_pdata={} # creata a dictionary\n",
    "pdata = [] # create a data list\n",
    "for i in range(len(wel_gdf)): # loop thorugh each well\n",
    "    wel = wel_gdf.loc[i] # Get the whole row of information for the well\n",
    "    welnum = i # set the well number to be the loop counter *** Note this must be consistent with the numbering approach used previously\n",
    "    r = -wel['Dewateri_2'] # assign the rate for the well\n",
    "    d = wel[\"Z\"] - wel[\"Pump Depth\"] # get well max pumping depth *** note this was in mbgl so subtracting from well surface elevation\n",
    "    l = 1.0 # setting the auto flow reducing window to 1.0 m above the max pump depth\n",
    "    settings = [[welnum,\"status\",\"active\"],[welnum,\"rate\",r],[welnum,\"rate_scaling\",d,l]] # creating the complete entry for a single well\n",
    "    pdata = [*pdata,*settings]\n",
    "maw_pdata[3] = pdata # all wells kick off 9 months prior to mining for this specific scenario which is stress period 4 in the model\n",
    "maw_pdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119b269-baf1-4439-99dc-a8e7172fb3a5",
   "metadata": {},
   "source": [
    "Now we can build our MAW package and an observation package as well. Note the way the observation file is created now. Because we have lots of different named boundaries - the well names in this case - we use a loop to create the entries for the observation package dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29272e2d-3f24-457d-827c-8f002b1ac5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build our package\n",
    "maw1 = flopy.mf6.ModflowGwfmaw(gwf,boundnames=True,\n",
    "                               save_flows=True,\n",
    "                               no_well_storage=True,\n",
    "                               shutdown_kappa=0.01,\n",
    "                               mfrcsv_filerecord=\"maw_reduce.csv\",\n",
    "                               nmawwells=len(well_nodes),\n",
    "                               packagedata= pakdata, \n",
    "                               connectiondata= condata , \n",
    "                               perioddata = maw_pdata, \n",
    "                               filename=\"flow_1.maw\",\n",
    "                               pname=\"maw1\")\n",
    "\n",
    "# Setup obs entries for each well\n",
    "ls =[]\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    name = wel[\"Bore\"]\n",
    "    ls.append((name,'maw',name)) # check the mF6io.pdf for other observations some advanced stress packages have many different types.\n",
    "\n",
    "print(ls)\n",
    "\n",
    "obs10_recarray = {\n",
    "    \"maw_obs.csv\": ls\n",
    "}\n",
    "maw1.obs.initialize(\n",
    "    filename=\"flow_1.maw.obs\",\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs10_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5432e-1689-48af-af69-a8efbc9de04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hdata from before\n",
    "ihd_array=np.ones_like(mg.botm)\n",
    "last_ssheads = np.loadtxt(\"iheads_array.txt\")\n",
    "ihd_array[:]=last_ssheads\n",
    "\n",
    "ic = flopy.mf6.ModflowGwfic(\n",
    "    gwf, pname=\"ic\", strt=ihd_array, filename=\"flow.ic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eb2b8-1a9f-4d9c-b32a-bba8524d73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae116570-464b-4838-a71d-11985cacab2c",
   "metadata": {},
   "source": [
    "# Visualising the dewatering simulation\r\n",
    "The purpose of the wells in this situation was to dewater the upper aquifer completely before mining could begin. We are going to check this by using plots of cross-sections. Note there are certainly other ways to do this serves as a nice example to demonstrate some post-processing using cross-sections of the model. To begin with we are going to use a shell of the planned mine pit in Raster format. Lets take a quick look at it while mapping the elevation of the shell to an array called \"spit-data\", which we will use later.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e17f25-8da1-4f35-8143-2098ade4baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spit_shell = os.path.join(gis_f,'SouthPitShell.tif')\n",
    "rio = Raster.load(spit_shell)\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "ax = rio.plot(ax=ax)\n",
    "plt.colorbar(ax.images[0], aspect=30)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg)\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"black\")\n",
    "spit_data = rio.resample_to_grid(\n",
    "    mg, band=rio.bands[0], method=\"nearest\"\n",
    ")\n",
    "ax.set_xlim(rio.bounds[0],rio.bounds[1])\n",
    "ax.set_ylim(rio.bounds[2],rio.bounds[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4014b-c07a-4d69-aaed-f019d55df41b",
   "metadata": {},
   "source": [
    "# Some plotting \r\n",
    "Here we will plot contours of hydraulic head and show the cross sections we will also be plotting. First we need the heads file from our model and then we will use the maximum and minimum values from that file to build a list of contour levels. We will use a mapview object and its built-in contour_array method to create the contour set. On top of that we will plot our cross-section line/s. For this we will use the mapview objects built in plot_shapefile feature. We also would like to indicate on the plot our cross section ends.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc18fa-7f8d-4bae-bf75-327741f14948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the heads file\n",
    "headfile = os.path.join(model_f,\"flow.hds\")\n",
    "hds = flopy.utils.binaryfile.HeadFile(headfile)\n",
    "# get the heads from the steady-state stress period\n",
    "h0 = hds.get_data((0,0))\n",
    "# get the heads from the final stress period- Note there is only one step in each stress period.\n",
    "h = hds.get_data((0,12))\n",
    "# get our contour levels using linspace\n",
    "levels = np.linspace(np.min(h),np.max(h),20)\n",
    "print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d455e2-3297-45ee-8273-ea11dc24bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A water table cross section\n",
    "#Lets plot a cross section of heads throough the model\n",
    "# first we show where the cross section is\n",
    "# Setup the figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "\n",
    "mapview = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) # create a mapview object for the current axis\n",
    "pc = mapview.plot_array(h, cmap='viridis') # plot the heads array\n",
    "colorbar = plt.colorbar(pc, aspect=30, shrink= 0.8) # create a colorbar\n",
    "contour_set = mapview.contour_array(h, levels=levels, colors='w',linewidths = 0.75) # plot some contours using our levels\n",
    "ax.clabel(contour_set, fmt='%.1f', colors='w', fontsize=8) # change the appearance of the contours\n",
    "\n",
    "\n",
    "# Plot a shapefile of a cross-section line\n",
    "shp = os.path.join(gis_f, \"cross_sectionAB.shp\") # path to the shapefile of a line I created in GIS\n",
    "# plot the cross section line\n",
    "patch_collection = mapview.plot_shapefile(shp, \n",
    "                                          radius=0, \n",
    "                                          lw=3, \n",
    "                                          edgecolor=\"red\", \n",
    "                                          facecolor=\"None\")\n",
    "ax.axis('off') # turn off the axes\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax,lay = patch_collection._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx,lby = patch_collection._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax,lay,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx,lby,'B',**text_kwargs,ha='left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844a9a1-d4ad-404f-aba6-3d00e738db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwf.get_package_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da15a33-0727-412f-936b-07f8c3c73c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drn5 = gwf.get_package('drn5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b168020-bbba-4fbc-903b-76e031076ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg=gwf.modelgrid\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, layer=0)\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"black\")\n",
    "pmv.plot_bc(package=drn5,kper=12, color='grey') # Note these drains are asigned elevations above the model and were used here to highlight the pit only\n",
    "pmv.plot_bc(package=maw1,color=\"green\" )\n",
    "\n",
    "# Plot a shapefile of a cross-section line\n",
    "shp = os.path.join(gis_f, \"cross_section_Spit.shp\")\n",
    "patch_collection1 = pmv.plot_shapefile(\n",
    "    shp, radius=0, lw=3, edgecolor=\"red\", facecolor=\"None\"\n",
    ")\n",
    "shp2 = os.path.join(gis_f, \"cross_section_Spit2.shp\")\n",
    "patch_collection2 = pmv.plot_shapefile(\n",
    "    shp2, radius=0, lw=3, edgecolor=\"blue\", facecolor=\"None\"\n",
    ")\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax,lay = patch_collection1._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx,lby = patch_collection1._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax,lay,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx,lby,'B',**text_kwargs,ha='left')\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax2,lay2 = patch_collection2._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx2,lby2 = patch_collection2._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax2,lay2,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx2,lby2,'B',**text_kwargs,ha='left')\n",
    "\n",
    "# set the plotting bounds to only the area of interest\n",
    "ax.set_xlim(rio.bounds[0]-250,rio.bounds[1]+250)\n",
    "ax.set_ylim(rio.bounds[2]-250,rio.bounds[3]+250)\n",
    "ax.set_title('South Pit Cross Sections')\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(plots_f,'Pit_cross_sections.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01826a-903c-4c7c-a765-b6ee33849df5",
   "metadata": {},
   "source": [
    "# USGSMap styling\n",
    "The crosss-section plots we will create using Flopy's inbuilt styling method. The approach to plotting a cross-section was covered in a previous workshop so should be familiar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66375593-4c27-4ac5-8270-be3ea58b1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import styles\n",
    "from flopy.plot import styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665351e8-4ac2-4232-91b6-d01660179c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a line for the cross section. I'm sure there is an easier way to do this but it works\n",
    "shp = os.path.join(gis_f, \"cross_section_Spit.shp\")\n",
    "gdf = gpd.read_file(shp)\n",
    "temp = gdf.geometry\n",
    "x1 = temp.get_coordinates().iloc[0].x\n",
    "y1 = temp.get_coordinates().iloc[0].y\n",
    "x2 = temp.get_coordinates().iloc[1].x\n",
    "y2 = temp.get_coordinates().iloc[1].y\n",
    "line = {'line':[(x1,y1),(x2,y2)]}\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6282536-9e86-471d-9a59-f1b8dc951831",
   "metadata": {},
   "outputs": [],
   "source": [
    "with styles.USGSMap():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 3), dpi=300, tight_layout=True)\n",
    "    extent = (0.0,690.0,320.0,420.0) # arrived at these through a bit of trial and error\n",
    "    xsect = flopy.plot.PlotCrossSection(modelgrid=mg, ax=ax, line=line, extent=extent)\n",
    "    # plot the surface and model grid\n",
    "    xsect.plot_surface(h0[0],color = \"green\", lw = 1.0, ls=':', label='initial')\n",
    "    wt1 = xsect.plot_surface(h[0], color=\"red\", lw=1.0, label='9-month dewater')\n",
    "    grd = xsect.plot_grid(lw=0.5)\n",
    "    styles.xlabel(label=\"x-position (m)\")\n",
    "    styles.ylabel(label=\"elevation (m)\")\n",
    "    styles.heading(heading=\"Simulated watertable in Layer 1\",fontsize=5)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels, ids = np.unique(labels, return_index=True)\n",
    "    handles = [handles[i] for i in ids]\n",
    "    leg = styles.graph_legend(handles = handles, labels=labels, fontsize=5)\n",
    "    styles.remove_edge_ticks(ax=ax)\n",
    "    styles.graph_legend_title(leg=leg,title=\"\")\n",
    "    styles.xlabel(ax=ax,label='cross-section A to B position (m)',fontsize=5)\n",
    "    styles.ylabel(ax=ax,label='cross-section elevation (m)',fontsize=5)\n",
    "    ax.set_aspect(3.0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(plots_f,'Dewater_cross_section.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d8737-c03a-4a1d-9558-273976a4c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = os.path.join(gis_f, \"cross_section_Spit2.shp\")\n",
    "gdf = gpd.read_file(shp)\n",
    "temp = gdf.geometry\n",
    "x1 = temp.get_coordinates().iloc[0].x\n",
    "y1 = temp.get_coordinates().iloc[0].y\n",
    "x2 = temp.get_coordinates().iloc[1].x\n",
    "y2 = temp.get_coordinates().iloc[1].y\n",
    "line = {'line':[(x1,y1),(x2,y2)]}\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d51df-b455-4768-bf20-3603cf3a237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with styles.USGSMap():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 3), dpi=300, tight_layout=True)\n",
    "    extent2 = (0.0,1150.0,330.0,400.0)\n",
    "    xsect2 = flopy.plot.PlotCrossSection(modelgrid=mg, ax=ax, line=line, extent=extent2)\n",
    "    # plot the surface and model grid\n",
    "    xsect2.plot_surface(h0[0],color = \"green\", lw = 1.0, ls=':', label='initial')\n",
    "    wt1 = xsect2.plot_surface(h[0], color=\"blue\", lw=1.0, label='9-month dewater')\n",
    "    grd = xsect2.plot_grid(lw=0.5) \n",
    "    #plt.legend()\n",
    "   # set labels using styles\n",
    "    styles.xlabel(label=\"x-position (m)\")\n",
    "    styles.ylabel(label=\"elevation (m)\")\n",
    "    styles.heading(heading=\"Simulated watertable\",fontsize=5)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels, ids = np.unique(labels, return_index=True)\n",
    "    handles = [handles[i] for i in ids]\n",
    "    leg = styles.graph_legend(handles = handles, labels=labels, fontsize=5)\n",
    "    styles.remove_edge_ticks(ax=ax)\n",
    "    styles.graph_legend_title(leg=leg,title=\"\")\n",
    "    styles.xlabel(ax=ax,label='cross-section A to B position (m)',fontsize=5)\n",
    "    styles.ylabel(ax=ax,label='cross-section elevation (m)',fontsize=5)\n",
    "    ax.set_aspect(3.0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(plots_f,'Dewater_cross_section2.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a3121-d1ac-47d8-bea6-e932874c6f87",
   "metadata": {},
   "source": [
    "# The Lake Package (LAK)\r\n",
    "The lake package can have different configurations within a model. We will only demonstrate the explicit approach, the reasons for which will become obvious as we do it. The explicit method requires that you deactivate model cells that comprise the lake and then create connections to the lake from the cells adjacent to those that were deactivated. Cell connection information is available via the discretization packages. It should be clear that with a structured model grid this is relatively straight forward but could become very complex with an unstructured or vertices type grid. We're going to setup a lake in the mine pit that we plotted cross sections for. So the first step will be to figure out which cells are inside our lake void and then deactivate them via IDOMAIN. Note this is not as simple as using the polygon to select boundary cells because now we have to account for 3 dimensions.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361fb19-e871-4309-9d2e-e5cae2e2dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the idea here is to check the elevation of the cell node and if it is above the pit\n",
    "# then it is inside the Lake and will have to be turned off.\n",
    "# This means that we will need an array that has the pit elevations in it. \n",
    "# We did this earlier for 2D when we sampled the raster to the grid\n",
    "spit_shell = os.path.join(gis_f,'SouthPitShell.tif')\n",
    "rio = Raster.load(spit_shell)\n",
    "spit_data = rio.resample_to_grid(\n",
    "    mg, band=rio.bands[0], method=\"nearest\"\n",
    ")\n",
    "# However, when mapping rasters smaller than the grid you can get errors. See the plot below.\n",
    "# we should only see values different from -99999 where the ratser was, ... but we don't.\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "mapview = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) # create a mapview object for the current axis\n",
    "pc = mapview.plot_array(spit_data, cmap='viridis') # plot the heads array\n",
    "ax.axis('off') # turn off the axes\n",
    "# the implication here is that our array of elevations has errors outside of the pit area that need to be corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca0541-0d55-4040-8853-059dfa9c4dd5",
   "metadata": {},
   "source": [
    "# Building an array filter\r\n",
    "The imported model used a shapefile to create a drain package (drn5) for the mine pit. You saw this plotted previously. So we can get the nodes (think array indices) for layer 1 that are in the pit. We will then build an array the same shape as our modelgrid bottoms and assign the pit shell raster elevations to all cells that fall inside the pit area in all layers. Outside of the pit area we will assign values greater than our maximum surface elevation. We then use this array as a filter to compare our with our model cell centres. If a model cell centre is above (has a value greater than) our filter array then it must be inside the pit\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbda37-660c-4635-86cb-ea1daaac8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get our in the pit for layer 1\n",
    "spit = os.path.join(gis_f,\"spit_outer_poly.shp\")\n",
    "spit_nodes = get_bnodes(spit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef83de3-cabc-4251-9cd8-e30b51dd5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean array the size of mg.botm\n",
    "mask = np.ones_like(spit_data,dtype=\"bool\") # this effectivley translates to True at all locations in the 2D array\n",
    "mask[spit_nodes.astype(\"int\")] = 0 # Change locations inside the pit to False in the 2D array, we don't want these values affected\n",
    "spit_data[mask]=1000.0 # change all values outside the pit to be 1000.0, which is above our model top elevation, only array indices flagged as true in the mask are affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf40a0-1a77-4364-b74c-eb183d4ef425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Matplotlib subplots to create a mutiple axes figure\n",
    "fig, axs = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 2, # I want three columns\n",
    "                        figsize = (16,6),\n",
    "                        subplot_kw={'aspect':'equal'},) # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=axs[0]) #creating a mapview object and specifying the axes\n",
    "pmv.plot_array(spit_data, cmap='viridis')\n",
    "axs[0].axis('off') # turn off the axes \n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=axs[1]) #creating a mapview object and specifying the axes\n",
    "pmv.plot_array(spit_data, cmap='viridis')\n",
    "axs[1].axis('off') # turn off the axes\n",
    "axs[1].set_xlim(rio.bounds[0]-250,rio.bounds[1]+250)\n",
    "axs[1].set_ylim(rio.bounds[2]-250,rio.bounds[3]+250)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54df0d-4c75-4814-a921-f57a576f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now we've fixed the errors so we can compare with cell centres, correct?\n",
    "# Not quite. The cell centres are a 3D array and we only have a 2D for now so we need to fix that.\n",
    "spit_data3D = np.vstack((spit_data,)*3) # Note how to create a repeating tuple, the comma is the key\n",
    "print(np.shape(spit_data3D), np.shape(mg.zcellcenters)) # now we can do our comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720078a1-5f80-4eaa-a022-e2fc4a216196",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpit = spit_data3D - mg.zcellcenters # anything with a negative value is in the pit void\n",
    "# now we can make an Idomain array to turn off cells in the pit void\n",
    "idom = np.zeros_like(mg.botm) # all deactivated\n",
    "idom[inpit>0]=1 # activate model cells outside of pit void\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 3, # I want three columns\n",
    "                        sharey=True, # they can share the Y-axis to save space\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(12, 5)) # setting figure size Note had to increase the x dimension here\n",
    "\n",
    "for i,ax in enumerate(axs):\n",
    "    pmv = flopy.plot.PlotMapView(modelgrid=mg, layer = i, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "    pmv.plot_grid(ax=ax, lw=0.3, color=\"black\") # plot the grid on the axes using linewidths = 0.3 and black lines\n",
    "    pmv.plot_array(idom[i])\n",
    "    ax.set_title(f'Model idomain Layer {i+1}') \n",
    "    ax.axis('off') # turn off the axes\n",
    "    ax.set_xlim(rio.bounds[0]-250,rio.bounds[1]+250)\n",
    "    ax.set_ylim(rio.bounds[2]-250,rio.bounds[3]+250)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f4ad2-bef2-49e4-b46b-1260d608936f",
   "metadata": {},
   "source": [
    "# The connection data\r\n",
    "This is the trickiest bit. However, if you get a feel for how to assign connections with the LAK package then you also know how to tackle nested models because the principle is the same. It may seem difficult but if you can grasp what information is stored in your modelgrid and how to access it then it can make your life much easier. To begin with we need to know what are the nodes adjacent to the inactive nodes. In a structured grid you could do a simple test because using unit increases or decreases in row and column to see if a neighbour of a deactivated cell is active thereby signalling a connection. With DISV and DISU we don't know the node numbers adjacent to our inactive cells, so how can we find teses ou?. Te followingscode blocks  serves as nt example for the benefits of a scripted modelling workflow.Unless the GUI you are using instead has a similar method for doing this you would have to set up all your connections by hand. Very painful.  Warning, this can be a bit of a brain drain so we'll take it slow.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b9ef2-b3ee-46c2-9f0c-de045cac3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need find to all active connections to the model grid from any deactivated cells\n",
    "i,j = np.where(idom == 0) # will return the layer numbers as an array i, the node numbers as an array j\n",
    "void_nodes = list(zip(i,j)) # zip i and j together to get the layer, node tuples for disv\n",
    "void_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed13cc2-3b6c-4020-b6ee-5f7980c97f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for disv any cell that shares two or more vertices with the node is connected.\n",
    "temp = {x[0]:list(zip(x[4:-1],x[5:])) for x in mg.cell2d} # creates vertex face pairs and links to nodes\n",
    "hcon_ls, vcon_ls = [],[] # initialise lists for horizntal and vertical connections\n",
    "for lay,node in void_nodes: # loop through all the deactivated nodes\n",
    "    faces = temp[node] # get the vertes face pairs\n",
    "    ls = [] # create an empty list to add active connections to\n",
    "    # The list comprehension below loops through the dictionary we created checking if a pair of vertices is present in forwadr or backaward sequence\n",
    "    ls = [key for key in temp.keys()\n",
    "          for face in faces          \n",
    "          if (face in temp[key] or (face[1],face[0]) in temp[key])]\n",
    "    ls = [x for x in ls if idom[lay][x]==1] # ls is filtered to only contain node numbers for this layer if they are acctive, idomain=1\n",
    "    if ls: # if there are any entries in ls\n",
    "        ls=[(lay,x) for x in ls] # unpack the sub-list into the full list\n",
    "        hcon_ls=[*hcon_ls,*ls] # create a list entry with the  the horizontal (layer,node) connections as a list\n",
    "    if lay!=mg.nlay-1: # check if we are in the last layer\n",
    "        if not (lay+1,node) in void_nodes: # if we are not in the last layer, check if an active vertical connection is present.\n",
    "            vcon_ls.append((lay+1,node)) # create a list entry with the vertical connection (layer,node) in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0ff09-3a7e-47bc-8ce2-309791ec627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the connection data to the acive cells we need the following as a list of lists\n",
    "# lakno = 1 in this case (user prescribed)\n",
    "# iconn = loop counter (get from counter)\n",
    "# cellid = cell the lake is connected to we get this from (node,layer) list\n",
    "# claktype = vertical or horizontal\n",
    "# bedleak = 'NONE' purely aquifer property control\n",
    "# belev = cell bottom elevation (get from mg.bottoms)\n",
    "# telev = assign as belev to internally set to top of cell\n",
    "# connlen = we know this because of quadtree grid spacing but does depend on your grid \n",
    "# Connwidth = will be the same as connlen in this case but does depend on your grid \n",
    "width = 40\n",
    "conlength = 40\n",
    "lakno = 0\n",
    "blk = 'NONE'\n",
    "condata = []\n",
    "\n",
    "for i,hcon in enumerate(hcon_ls):\n",
    "    cell_bot = mg.botm[hcon[0],hcon[1]]\n",
    "    condata.append([lakno,i,hcon,\"HORIZONTAL\",blk,cell_bot,cell_bot,conlength,width])\n",
    "i+=1\n",
    "for j,vcon in enumerate(vcon_ls):\n",
    "    cell_bot = mg.botm[vcon[0],vcon[1]]\n",
    "    condata.append([lakno,i+j,hcon,\"VERTICAL\",blk,cell_bot,cell_bot,conlength,width])\n",
    "condata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb80cfa-b072-4ff3-a367-1535f77cb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now lets add the Lake Package to the model\n",
    "istage = 355.0 # approximate steady-state head elevation without lake\n",
    "avg_rain = 6.8E-03 # approximatley 2500 mm/yr direct interception\n",
    "evap = 0.004 # 4 mm/d or aprroximatley 1500 mm/yr\n",
    "pakdata = [0,istage,len(condata),'Spit']\n",
    "#tables = [0,'Spit_table.dat'] # You can provide a stage-volume-area lookup table if you need to\n",
    "\n",
    "# Building a stress period dictionary as per normal\n",
    "lak_spd={}\n",
    "lak_spd[0] = [[0,\"status\",\"CONSTANT\"],[0,\"stage\",istage]]\n",
    "lak_spd[1] = [[0,\"status\",\"ACTIVE\"],[0, \"rainfall\", avg_rain],[0,\"evaporation\",evap]]\n",
    "\n",
    "lak = flopy.mf6.ModflowGwflak(\n",
    "    gwf,\n",
    "    boundnames=True,\n",
    "    save_flows=True,\n",
    "    stage_filerecord='Spit_lak_stage.out',\n",
    "    budget_filerecord='Spit_budget.out',\n",
    "    budgetcsv_filerecord='Spit_budget.csv',\n",
    "    package_convergence_filerecord='Spit_convergence.csv',\n",
    "    pname=\"Spit_lak\",\n",
    "    time_conversion=86400.00,\n",
    "    length_conversion=1.0,\n",
    "    mover=False,\n",
    "    print_stage=False,\n",
    "    nlakes=1,\n",
    "    noutlets=0,\n",
    "    #ntables=1, # if you have an SVA table for your lake/s then you turn this on\n",
    "    packagedata=pakdata,\n",
    "    connectiondata=condata,\n",
    "    #tables=tables,\n",
    "    outlets=None,\n",
    "    perioddata=lak_spd,\n",
    ")\n",
    "\n",
    "obs_file = \"flow.lak.obs\"\n",
    "csv_file = obs_file + \".csv\"\n",
    "obs_dict = {\n",
    "    csv_file: [\n",
    "        ('Spit_STG', \"stage\", (0,)),\n",
    "        ('Spit_VOL', \"volume\", (0,)),\n",
    "        ('Spit_SA', \"surface-area\", (0,)),\n",
    "        ('Spit_WA', \"wetted-area\", 'Spit'),\n",
    "        ('Spit_CND', \"conductance\", 'Spit'),\n",
    "        ('Spit_RN', \"rainfall\", (0,)),\n",
    "        ('Spit_EV', \"evaporation\", (0,)),\n",
    "        ('Spit_AQ', \"lak\", 'Spit'),\n",
    "    ]\n",
    "}\n",
    "lak.obs.initialize(\n",
    "    filename=obs_file, digits=10, print_input=True, continuous=obs_dict\n",
    ")\n",
    "\n",
    "lak.write()\n",
    "lak.obs.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2085b3-fa9f-496b-9acb-9068c1608b8f",
   "metadata": {},
   "source": [
    "# Ouch that was painful\r\n",
    "Letâ€™s run it for fun and have a look at the output table. But first we are going to setup the output control to save our budget to a csv that we can see for plotting later\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f37185-7454-41f6-9c72-585ff53a0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwf.remove_package(\"MAW\")\n",
    "oc = flopy.mf6.ModflowGwfoc(gwf,budgetcsv_filerecord='mybudget.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8581bf-04fe-4b42-b675-2fe947c5b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecd7de-af92-4158-a9ef-7c6e40be5ea7",
   "metadata": {},
   "source": [
    "# Alternative method for accessing budget data\r\n",
    "In addition to loading your saved csv into a pandas dataframe you can also load the information directly with Flopy methods. Here we use the built in .output.budgetcsv() method to retrieve the LAK package list file budget entries as a csv. We will leverage the .output feature of Flopy more in subsequent sessions\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1a5ea-169f-43f3-9011-e8ed271811df",
   "metadata": {},
   "outputs": [],
   "source": [
    "budcsv = gwf.output.budgetcsv()\n",
    "budcsv.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef9158-0159-48fe-b947-149dbb956069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the record array data-type information to list specific budget record array columns\n",
    "budcsv.data['LAK(SPIT_LAK)_OUT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119b881-a51b-459a-9fa5-e679eb722df2",
   "metadata": {},
   "source": [
    "# That's all folks\n",
    "Next session will be on solute and variable density transport. See you then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745127d1-7214-4897-b839-18a5e23ef648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
