{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4aca80-7169-44cf-81a5-cd71069fce05",
   "metadata": {},
   "source": [
    "# Workshop 5\n",
    "Hi and welcome to the fifth workshop. In this session we will take a look at a couple of the advanced stress packages because they tend to have input requirements that are somewhat uncommon to the regular stress packages. Specifically we will focus on the lake package (LAK) and the multi-aquifer well package (MAW) to demonstrate how the different data requirements for these packages are developed and used in Flopy objects. We picked the MAW because of applicability and the LAK because it also introduces cell connectivity data input similar to the GWF-GWF package used for linking mutiple models in MF6. Once you have a grasp of the input requirements for these packages the remaining advanced stress packages should not pose a significant obstacle. In addition to the advanced stress package creation we will introduce some of the inbuilt post-processing capabilities of Flopy and provide applied use examples of how they can be used to good effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09bfcad-a557-46d3-8ac4-a3bee5ff9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "from flopy.discretization import VertexGrid\n",
    "from flopy.utils import Raster\n",
    "from flopy.utils import GridIntersect\n",
    "from flopy.utils.gridgen import Gridgen\n",
    "gridgen_exe = \"gridgen\"\n",
    "if platform.system() in \"Windows\":\n",
    "    gridgen_exe += \".exe\"\n",
    "gridgen_exe = flopy.which(\"gridgen\")\n",
    "if gridgen_exe is None:\n",
    "    msg = (\n",
    "        \"Warning, gridgen is not in your path. \"\n",
    "        \"When you create the griden object you will need to \"\n",
    "        \"provide a full path to the gridgen binary executable.\"\n",
    "    )\n",
    "    print(msg)\n",
    "else:\n",
    "    print(\"gridgen executable was found at: {}\".format(gridgen_exe))\n",
    "\n",
    "print(f\"Pandas version = {pd.__version__}\")\n",
    "print(f\"Numpy version = {np.__version__}\")\n",
    "print(f\"Flopy version = {flopy.__version__}\")\n",
    "print(f\"Matplotlib version = {matplotlib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c49bc-0942-4854-a431-ec5bbec1c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws5 = os.path.join('workshop_5') # here we are making a path not creating the folder\n",
    "gis_f = os.path.join(ws5,'GIS') # creating a sub-directory path for our gis input/output\n",
    "model_f = os.path.join(ws5,'model') # creating a sub-directory path for our model input/output\n",
    "plots_f = os.path.join(ws5,'plots') # creating a sub-directory path for our plots\n",
    "for path in [ws5,gis_f,model_f,plots_f]:\n",
    "    if os.path.exists(path): # here we are asking if the path exists on the computer. \n",
    "        shutil.rmtree(path)# if it does exist, delete it and all the files in it\n",
    "        os.mkdir(path) # then remake it\n",
    "    else:\n",
    "        os.mkdir(path) # if it doesn't exist then make the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0dda4-6a6f-4486-a0fd-30afe07358f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import ws5_model1\n",
    "sim, gwf = ws5_model1(ws5,gis_f,model_f,plots_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696597f-60bb-47a5-864a-220cf1da01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16eb62-288b-4475-8173-573db47842b9",
   "metadata": {},
   "source": [
    "# A summary of the budget\n",
    "Budget summaries should be checked consistently throughout the model development process as a rule. Recall that you configure the frequency of the summary printed to the list file via the OC package demonstarted in the previous workshop. Here we are going to use a convinient utility function of Flopy to load the list file and then convert the budget summaries into data frames that we can then use for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee8a08-db6f-4264-81a6-c8a46d4f308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at budget summary\n",
    "lst = flopy.utils.Mf6ListBudget(os.path.join(model_f,\"flow.lst\")) # create a list file object for the current model run\n",
    "\n",
    "df_flux, df_vol = lst.get_dataframes(start_datetime='31-12-2023') # use a method of the listfile object to convert the budget summaries to data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b776ea-b309-4705-9913-5c138ca72acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720af4db-b631-4d81-ae4a-4d7d7825eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b09de-2523-4e8d-920a-b92a419e1b95",
   "metadata": {},
   "source": [
    "Staring at numbers may be tedious for some people who might prefer something visual. So lets create a summary plot of the budget fluxes. We first seperate ins and outs using Pandas groupby dataframe method using axis=1, which means we are moving across the columns. What we pass into the groupby method is a lambda function. The lambda function is going to return the string trailing the final underscore in each column name. The groupby method can provide you with lots of information but we are only interested in the groups and their members so the final .groups in the expression below will return a dictionary with the group as a key and the list of group members as the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d37314-3659-448d-bde1-36dd7aa4d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_flux.groupby(lambda x: x.split(\"_\")[-1], axis=1).groups # splitting by the underscore to get in, out, or discrepancy groups.\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4f3fe-989b-42fa-958d-389b8d0c5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flux_in = df_flux.loc[:, groups[\"IN\"]] # create a dataframe view of the fluxes into the model\n",
    "df_flux_in.columns = df_flux_in.columns.map(lambda x: x.split(\"_\")[0]) # change the columns names here to exclude the \"_IN\"\n",
    "# note use of the map method, which can be loosley translated to \"apply to all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b81a97-f314-4232-8c65-c8c919b228ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for outs\n",
    "df_flux_out = df_flux.loc[:, groups[\"OUT\"]]\n",
    "df_flux_out.columns = df_flux_out.columns.map(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be796575-c254-454b-a9c0-c7c0d60cc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the outs from the ins\n",
    "df_flux_delta = df_flux_in - df_flux_out\n",
    "# change from kL/d to ML/d\n",
    "df_flux_delta = df_flux_delta*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c502c-1f05-447c-8128-2322b8bbb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot a specific stress period using Pandas dataframe plot methods\n",
    "spnum = 12\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax) # note using stress period number here instead of date\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b459f-56dc-4d50-af8c-6641b83134af",
   "metadata": {},
   "source": [
    "Recharge and ET dominate the plot making a comparison of other fluxes difficult. You can solve this by dropping them from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc177b-6625-4333-b7c6-5b86989e937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta = df_flux_delta.drop(columns=[\"RCHA\",\"EVTA\"]) # note these are huge in comparison so we are dropping them for now.\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax)\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb86c1c-fc58-430f-9c33-15bba6d5302d",
   "metadata": {},
   "source": [
    "# Saving the heads for subsequent simualtions\n",
    "This was demonstrated but not used in the previous workshop. We will be running our mode again so lets save the initial condition heads for use again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e333dc9-6c9f-4c89-b0a1-83bd9d972c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "headfile = os.path.join(model_f,\"flow.hds\")\n",
    "hds = flopy.utils.binaryfile.HeadFile(headfile)\n",
    "h = hds.get_data((0,0))\n",
    "np.savetxt(\"iheads_array.txt\",h[0]) # note this is not saved to the model folder because if I choose to rerun the script from scrtach it will be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051e239-3a40-4484-a843-f52560ad4744",
   "metadata": {},
   "source": [
    "# MAW package\n",
    "Take a look at the MAW package input file in the MF6io.pdf document. You will notice that in addition to an options section you have to specify three other datasets. This includes package data, connection data and stress period data. In this example we will use a shapefile of bore locations to intersect the model grid and obtain the relevant nodes for each well. A function that we used to assign boundary conditions via intersections will be used. This function works well for lines points and polygons but will cause problems if you have mutiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb2ab0-3b52-40ea-a42d-123abf49ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "def get_bnodes(shpfyl): # works with single and multiple line strings\n",
    "    ix = GridIntersect(mg, method=\"vertex\") # build our intersection object we will be applyitng this to a vertex grid only\n",
    "    poly = gpd.read_file(shpfyl).geometry # read in the shapefile\n",
    "    if len(poly)==1: # if the feature only has one entry\n",
    "        return(ix.intersect(poly[0]).cellids) # note this is an array\n",
    "    else: \n",
    "        ls = [] # if the feature has mutiple items i.e. points or multi-line strings\n",
    "        for item in poly: # loop through the different geometries of each item\n",
    "            nums = ix.intersect(item).cellids\n",
    "            ls = [*ls,*nums]\n",
    "        return(np.asarray(ls)) # # this will also be an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4c5bb-4392-49fe-bfc6-b77a61271a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in wells for explicit dewatering simulation\n",
    "mg = gwf.modelgrid\n",
    "wels = os.path.join(gis_f,\"dewatering_wells.shp\")\n",
    "well_nodes = get_bnodes(wels)\n",
    "wel_gdf = gpd.read_file(wels)\n",
    "wel_gdf['node'] = well_nodes\n",
    "wel_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2d842-9fd6-4e96-a537-c4787a86bda6",
   "metadata": {},
   "source": [
    "Bore and pump depth are included in the shapefile so we will use this to configure our simulated bores. Note the MAW package offers many different options for well simualtion behaviour and it is useful to know how you cen best utilize the package for your specific simulation. However, in this instance we will adopt the 'THEIM' behaviour option. Each well has a single package data entry but can have multiple connection data entries depending on the different layers intercepted by the screen interval. We only have a three layer model and the wells may or may not reach layer 2. The algorithm below will use the layer elevation data and the bore drill depth to determine the number of connections needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f14e8-c028-40d4-a050-36679d7dad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 0.3 # assume all bores have a radius of 0.3 m\n",
    "condeqn = \"THEIM\" # the string for setting the MAW behaviour option\n",
    "pakdata = [] # initialze some empty lists for package data and connection data\n",
    "condata = []\n",
    "for i in range(len(wel_gdf)): # for each well\n",
    "    welnum = i # assign a unique well number\n",
    "    wel = wel_gdf.loc[i] # get the row entry for the well in the dataframe form the shapefile\n",
    "    bottom = wel[\"Z\"] - wel[\"Bore Depth\"] # Work out the bottom elevation of the well\n",
    "    count = 0 # set a count for the number of connections\n",
    "    node = wel[\"node\"] # this is the node in layer 1 that we got from our function\n",
    "    start = mg.top[node] # set a starting elevation\n",
    "    name = wel[\"Bore\"] # get the well name\n",
    "    for lay in range(3): # nlay =  3 Now loop thorugh each layers bottom elevation for the same node\n",
    "        if mg.botm[lay][node]>bottom: # conditional on the layer elevation\n",
    "            entry2 = (welnum,count,(lay,node),1,1,1,1)\n",
    "            condata.append(entry2)\n",
    "            count+=1\n",
    "    entry = (welnum,rad,bottom,start,condeqn,count,name)\n",
    "    pakdata.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2268b-a7dd-40b4-82aa-30f6adad34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pakdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabded8a-fd7f-46bb-8192-d1769c2ba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "condata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894efd4-e65e-49d8-a498-922308273133",
   "metadata": {},
   "source": [
    "So it looks like some of the wells are only in the first layer while others are in the second layer. Once we have the package and connection data we can configure the stress period data. The rates needed from the shapefile are in the column named Dewateri_2. The line to pay special attention to is the \"settings =\" line. Note how the entry for single well is a list of lists, where each netsed list has the well number as the first entry then a keyword followed by the settings specific to that keyword. For example the keyword \"status\" requires another string as the setting, in this case \"active\". The keyword \"rate_scaling\" requires two float values d and l. If you look in the MF6io.pdf document you can see what each keyword requires as its settings. Also very important is to understand how advanced stress packages turn on and off differs from other stress packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17111b8f-5703-4fb2-9530-152b19a08d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then finally we also need period data configured for each well\n",
    "maw_pdata={} # creata a dictionary\n",
    "pdata = [] # create a data list\n",
    "for i in range(len(wel_gdf)): # loop thorugh each well\n",
    "    wel = wel_gdf.loc[i] # Get the whole row of information for the well\n",
    "    welnum = i # set the well number to be the loop counter *** Note this must be consistent with the numbering approach used previously\n",
    "    r = -wel['Dewateri_2'] # assign the rate for the well\n",
    "    d = wel[\"Z\"] - wel[\"Pump Depth\"] # get well max pumping depth *** note this was in mbgl so subtracting from well surface elevation\n",
    "    l = 1.0 # setting the auto flow reducing window to 1.0 m above the max pump depth\n",
    "    settings = [[welnum,\"status\",\"active\"],[welnum,\"rate\",r],[welnum,\"rate_scaling\",d,l]] # creating the complete entry for a single well\n",
    "    pdata = [*pdata,*settings]\n",
    "maw_pdata[3] = pdata # all wells kick off 9 months prior to mining for this specific scenario which is stress period 4 in the model\n",
    "maw_pdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea68ee5-ace5-41d6-bdec-c4bed3a5cda1",
   "metadata": {},
   "source": [
    "Now we can build our MAW package and an observation package as well. Note the way the observation file is created now. Because we have lots of different named boundaries - the well names in this case - we use a loop to create the entries for the observation package dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29272e2d-3f24-457d-827c-8f002b1ac5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build our package\n",
    "maw1 = flopy.mf6.ModflowGwfmaw(gwf,boundnames=True,\n",
    "                               save_flows=True,\n",
    "                               no_well_storage=True,\n",
    "                               shutdown_kappa=0.01,\n",
    "                               mfrcsv_filerecord=\"maw_reduce.csv\",\n",
    "                               nmawwells=len(well_nodes),\n",
    "                               packagedata= pakdata, \n",
    "                               connectiondata= condata , \n",
    "                               perioddata = maw_pdata, \n",
    "                               filename=\"flow_1.maw\")\n",
    "\n",
    "# Setup obs entries for each well\n",
    "ls =[]\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    name = wel[\"Bore\"]\n",
    "    ls.append((name,'maw',name)) # check the mF6io.pdf for other observations some advanced stress packages have many different types.\n",
    "\n",
    "print(ls)\n",
    "\n",
    "obs10_recarray = {\n",
    "    \"maw_obs.csv\": ls\n",
    "}\n",
    "maw1.obs.initialize(\n",
    "    filename=\"flow_1.maw.obs\",\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs10_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5432e-1689-48af-af69-a8efbc9de04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hdata from before\n",
    "ihd_array=np.ones_like(mg.botm)\n",
    "last_ssheads = np.loadtxt(\"iheads_array.txt\")\n",
    "ihd_array[:]=last_ssheads\n",
    "\n",
    "ic = flopy.mf6.ModflowGwfic(\n",
    "    gwf, pname=\"ic\", strt=ihd_array, filename=\"flow.ic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eb2b8-1a9f-4d9c-b32a-bba8524d73f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34e4c4-2915-4ad7-8f0e-d690cf86ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at budget summary\n",
    "lst = flopy.utils.Mf6ListBudget(os.path.join(model_f,\"flow.lst\"))\n",
    "start_datetime='31-12-2023'\n",
    "df_flux, df_vol = lst.get_dataframes()\n",
    "# use the spnum variable to select a specific stress period\n",
    "spnum = 12\n",
    "groups = df_flux.groupby(lambda x: x.split(\"_\")[-1], axis=1).groups\n",
    "df_flux_in = df_flux.loc[:, groups[\"IN\"]]\n",
    "df_flux_in.columns = df_flux_in.columns.map(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "df_flux_out = df_flux.loc[:, groups[\"OUT\"]]\n",
    "df_flux_out.columns = df_flux_out.columns.map(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "df_flux_delta = df_flux_in - df_flux_out\n",
    "df_flux_delta = df_flux_delta*0.001\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta = df_flux_delta.drop(columns=[\"RCHA\",\"EVTA\"]) # note these are huge in comparison so we are dropping them for now.\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax)\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88a474-3f5d-404b-b430-84f1f560a5b4",
   "metadata": {},
   "source": [
    "The purpose of the wells in this situation was to dewater the upper aquifer completley before mining could begin. We are going to check this by using plots of cross-sections. Note there are certainly other ways to do this serves as a nice example to demonstrate some post-processing using cross-sections of the model. To begin with we are going to use a shell of the planned mine pit in Raster format. Lets take a quick look at it while maping the elevation of the shell to an array called \"spit-data\", which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e17f25-8da1-4f35-8143-2098ade4baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spit_shell = os.path.join(gis_f,'SouthPitShell.tif')\n",
    "rio = Raster.load(spit_shell)\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "ax = rio.plot(ax=ax)\n",
    "plt.colorbar(ax.images[0], aspect=30)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg)\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"black\")\n",
    "spit_data = rio.resample_to_grid(\n",
    "    mg, band=rio.bands[0], method=\"nearest\"\n",
    ")\n",
    "ax.set_xlim(rio.bounds[0],rio.bounds[1])\n",
    "ax.set_ylim(rio.bounds[2],rio.bounds[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf416b-db01-4414-a33c-ce68bcbd3ba6",
   "metadata": {},
   "source": [
    "# Plotting contours of hydraulic head and showing the cross esctions we will be plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc18fa-7f8d-4bae-bf75-327741f14948",
   "metadata": {},
   "outputs": [],
   "source": [
    "headfile1 = os.path.join(model_f,\"flow.hds\")\n",
    "hds = flopy.utils.binaryfile.HeadFile(headfile)\n",
    "h0 = hds.get_data((0,0))\n",
    "h = hds.get_data((0,12))\n",
    "\n",
    "levels = np.linspace(np.min(h),np.max(h),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d455e2-3297-45ee-8273-ea11dc24bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A water table cross section\n",
    "#Lets plot a cross section of heads throough the model\n",
    "# first we show where the cross section is\n",
    "# Setup the figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "\n",
    "mapview = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) # create a mapview object for the current axis\n",
    "pc = mapview.plot_array(h, cmap='viridis') # plot the heads array\n",
    "colorbar = plt.colorbar(pc, aspect=30, shrink= 0.8) # create a colorbar\n",
    "contour_set = mapview.contour_array(h, levels=levels, colors='w',linewidths = 0.75) # plot some contours using our levels\n",
    "ax.clabel(contour_set, fmt='%.1f', colors='w', fontsize=8) # change the appearance of the contours\n",
    "\n",
    "\n",
    "# Plot a shapefile of a cross-section line\n",
    "shp = os.path.join(gis_f, \"cross_sectionAB.shp\") # path to the shapefile of a line I created in GIS\n",
    "# plot the cross section line\n",
    "patch_collection = mapview.plot_shapefile(shp, \n",
    "                                          radius=0, \n",
    "                                          lw=3, \n",
    "                                          edgecolor=\"red\", \n",
    "                                          facecolor=\"None\")\n",
    "ax.axis('off') # turn off the axes\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax,lay = patch_collection._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx,lby = patch_collection._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax,lay,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx,lby,'B',**text_kwargs,ha='left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844a9a1-d4ad-404f-aba6-3d00e738db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwf.get_package_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da15a33-0727-412f-936b-07f8c3c73c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drn5 = gwf.get_package('drn5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b168020-bbba-4fbc-903b-76e031076ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg=gwf.modelgrid\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, layer=0)\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"black\")\n",
    "pmv.plot_bc(package=drn5,kper=12, color='grey')\n",
    "pmv.plot_bc(package=maw1,color=\"green\" )\n",
    "\n",
    "# Plot a shapefile of a cross-section line\n",
    "shp = os.path.join(gis_f, \"cross_section_Spit.shp\")\n",
    "patch_collection1 = pmv.plot_shapefile(\n",
    "    shp, radius=0, lw=3, edgecolor=\"red\", facecolor=\"None\"\n",
    ")\n",
    "shp2 = os.path.join(gis_f, \"cross_section_Spit2.shp\")\n",
    "patch_collection2 = pmv.plot_shapefile(\n",
    "    shp2, radius=0, lw=3, edgecolor=\"blue\", facecolor=\"None\"\n",
    ")\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax,lay = patch_collection1._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx,lby = patch_collection1._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax,lay,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx,lby,'B',**text_kwargs,ha='left')\n",
    "\n",
    "# position the labels for the cross section lines\n",
    "lax2,lay2 = patch_collection2._paths[0].vertices[0] # depending on the line this may not be the correct vertex\n",
    "lbx2,lby2 = patch_collection2._paths[0].vertices[1] # same again so be careful with this approach\n",
    "text_kwargs = dict(fontsize = 16, color = 'k')\n",
    "plt.text(lax2,lay2,'A',**text_kwargs,ha='right')\n",
    "plt.text(lbx2,lby2,'B',**text_kwargs,ha='left')\n",
    "\n",
    "ax.set_xlim(rio.bounds[0]-250,rio.bounds[1]+250)\n",
    "ax.set_ylim(rio.bounds[2]-250,rio.bounds[3]+250)\n",
    "ax.set_title('South Pit Cross Sections')\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "plt.tight_layout()\n",
    "fig.savefig('Pit_tailings_coverage.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461fd5e-d84e-4e69-ade1-2e2cbf6e27c7",
   "metadata": {},
   "source": [
    "# USGSMap styling\n",
    "The crosss section plots we will create using Flopy's inbuilt styling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66375593-4c27-4ac5-8270-be3ea58b1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import styles\n",
    "from flopy.plot import styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5577b-0bf3-4735-b871-4d2bad92e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the extents for the plot\n",
    "pit1500 = os.path.join(gis_f,\"pits_buffer_1500.shp\")\n",
    "gdf1 = gpd.read_file(pit1500)\n",
    "gdf1.set_crs(epsg=32629)\n",
    "extents = gdf1.geometry.total_bounds\n",
    "extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665351e8-4ac2-4232-91b6-d01660179c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a line for the cross section\n",
    "shp = os.path.join(gis_f, \"cross_section_Spit.shp\")\n",
    "gdf = gpd.read_file(shp)\n",
    "temp = gdf.geometry\n",
    "x1 = temp.get_coordinates().iloc[0].x\n",
    "y1 = temp.get_coordinates().iloc[0].y\n",
    "x2 = temp.get_coordinates().iloc[1].x\n",
    "y2 = temp.get_coordinates().iloc[1].y\n",
    "line = {'line':[(x1,y1),(x2,y2)]}\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6282536-9e86-471d-9a59-f1b8dc951831",
   "metadata": {},
   "outputs": [],
   "source": [
    "with styles.USGSMap():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 3), dpi=300, tight_layout=True)\n",
    "    extent = (0.0,690.0,320.0,420.0)\n",
    "    xsect = flopy.plot.PlotCrossSection(modelgrid=mg, ax=ax, line=line, extent=extent)\n",
    "    # plot the surface and model grid\n",
    "    xsect.plot_surface(h0[0],color = \"green\", lw = 1.0, ls=':', label='initial')\n",
    "    wt1 = xsect.plot_surface(h[0], color=\"red\", lw=1.0, label='9-month dewater')\n",
    "    grd = xsect.plot_grid(lw=0.5)\n",
    "    styles.xlabel(label=\"x-position (m)\")\n",
    "    styles.ylabel(label=\"elevation (m)\")\n",
    "    styles.heading(heading=\"Simulated watertable in Layer 1\",fontsize=5)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels, ids = np.unique(labels, return_index=True)\n",
    "    handles = [handles[i] for i in ids]\n",
    "    leg = styles.graph_legend(handles = handles, labels=labels, fontsize=5)\n",
    "    styles.remove_edge_ticks(ax=ax)\n",
    "    styles.graph_legend_title(leg=leg,title=\"\")\n",
    "    styles.xlabel(ax=ax,label='cross-section A to B position (m)',fontsize=5)\n",
    "    styles.ylabel(ax=ax,label='cross-section elevation (m)',fontsize=5)\n",
    "    ax.set_aspect(3.0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(plots_f,'Dewater_cross_section.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d8737-c03a-4a1d-9558-273976a4c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = os.path.join(gis_f, \"cross_section_Spit2.shp\")\n",
    "gdf = gpd.read_file(shp)\n",
    "temp = gdf.geometry\n",
    "x1 = temp.get_coordinates().iloc[0].x\n",
    "y1 = temp.get_coordinates().iloc[0].y\n",
    "x2 = temp.get_coordinates().iloc[1].x\n",
    "y2 = temp.get_coordinates().iloc[1].y\n",
    "line = {'line':[(x1,y1),(x2,y2)]}\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d51df-b455-4768-bf20-3603cf3a237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with styles.USGSMap():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 3), dpi=300, tight_layout=True)\n",
    "    extent2 = (0.0,1150.0,330.0,400.0)\n",
    "    xsect2 = flopy.plot.PlotCrossSection(modelgrid=mg, ax=ax, line=line, extent=extent2)\n",
    "    # plot the surface and model grid\n",
    "    xsect2.plot_surface(h0[0],color = \"green\", lw = 1.0, ls=':', label='initial')\n",
    "    wt1 = xsect2.plot_surface(h[0], color=\"blue\", lw=1.0, label='9-month dewater')\n",
    "    grd = xsect2.plot_grid(lw=0.5) \n",
    "    #plt.legend()\n",
    "   # set labels using styles\n",
    "    styles.xlabel(label=\"x-position (m)\")\n",
    "    styles.ylabel(label=\"elevation (m)\")\n",
    "    styles.heading(heading=\"Simulated watertable\",fontsize=5)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels, ids = np.unique(labels, return_index=True)\n",
    "    handles = [handles[i] for i in ids]\n",
    "    leg = styles.graph_legend(handles = handles, labels=labels, fontsize=5)\n",
    "    styles.remove_edge_ticks(ax=ax)\n",
    "    styles.graph_legend_title(leg=leg,title=\"\")\n",
    "    styles.xlabel(ax=ax,label='cross-section A to B position (m)',fontsize=5)\n",
    "    styles.ylabel(ax=ax,label='cross-section elevation (m)',fontsize=5)\n",
    "    ax.set_aspect(3.0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(os.path.join(plots_f,'Dewater_cross_section2.png'),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136e6a3-6a69-4439-96e5-81bf79ccc14d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
