{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b966082-e985-43a4-9ec6-2fb75f5f51eb",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Hi and welcome to Workshop 8. In this session we will step through an applied example of a real world project where the majority of the demonstrated approaches to creating input files for a MODFLOW-6 type model are used. Most of the notebook will be familiar to you if you completed the previous Workshops. There will be a few new things but these are mostly associated with adding complexity to model behaviour through transient boundary conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d61b72-c26b-4332-841f-5c7454d9f4e8",
   "metadata": {},
   "source": [
    "# The project brief\n",
    "The project we will be investigating is a planned mining operation that is in feasibility stage. Consequently, the aim of the modelling is exploratory. This means that there is limited data and we will build a model for the express purpose to perform a Monte-Carlo of the prior model parameter ranges. The modelling specific objectives of the investigation are to provide conservative but plausible range of mine inflows into two mine pits, examine the drawdown propagation associated with the proposed operation and its potential to affect third party water users plus provide some preliminary indication of the migration of any solutes that may leach from closure operations in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4998e46c-a847-4a69-809c-89f7e2fe37a9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee21f2d-02b0-4cb0-94be-038b67905ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "from flopy.discretization import VertexGrid\n",
    "from flopy.utils import Raster\n",
    "from flopy.utils import GridIntersect\n",
    "from flopy.utils.gridgen import Gridgen\n",
    "gridgen_exe = \"gridgen\"\n",
    "if platform.system() in \"Windows\":\n",
    "    gridgen_exe += \".exe\"\n",
    "gridgen_exe = flopy.which(\"gridgen\")\n",
    "if gridgen_exe is None:\n",
    "    msg = (\n",
    "        \"Warning, gridgen is not in your path. \"\n",
    "        \"When you create the griden object you will need to \"\n",
    "        \"provide a full path to the gridgen binary executable.\"\n",
    "    )\n",
    "    print(msg)\n",
    "else:\n",
    "    print(\"gridgen executable was found at: {}\".format(gridgen_exe))\n",
    "\n",
    "print(f\"Pandas version = {pd.__version__}\")\n",
    "print(f\"Numpy version = {np.__version__}\")\n",
    "print(f\"Flopy version = {flopy.__version__}\")\n",
    "print(f\"Matplotlib version = {mpl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee9f1f-6528-46ed-800b-8d2d611a69d2",
   "metadata": {},
   "source": [
    "# Project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307038a2-6039-4d55-934f-cce9b0a73934",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws8 = os.path.join('workshop_8') # here we are making a path not creating the folder\n",
    "gis_f = os.path.join(ws8,'GIS') # creating a sub-directory path for our gis input/output\n",
    "model_f = os.path.join(ws8,'model') # creating a sub-directory path for our model input/output\n",
    "plots_f = os.path.join(ws8,'plots') # creating a sub-directory path for our plots\n",
    "for path in [ws8,gis_f,model_f,plots_f]:\n",
    "    if os.path.exists(path): # here we are asking if the path exists on the computer. \n",
    "        shutil.rmtree(path)# if it does exist, delete it and all the files in it\n",
    "        os.mkdir(path) # then remake it\n",
    "    else:\n",
    "        os.mkdir(path) # if it doesn't exist then make the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c241b1-3499-4652-ba97-38432111d452",
   "metadata": {},
   "source": [
    "# Copy model shapefiles for grid creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d964ac-b523-4f9a-a4a5-bb8768f60231",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = os.path.join('files','disv_shapefiles') # path to shapefiles for this example\n",
    "flist = [x for x in os.listdir(shp_path)] # create a list of all the shapefiles\n",
    "for file in flist:\n",
    "    shutil.copyfile(os.path.join(shp_path,file),os.path.join(gis_f,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc5d66-c352-4b2f-9ed1-0d91d6da4034",
   "metadata": {},
   "source": [
    "# Gridgen model grid setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7b571-047c-4a5c-94f5-8b0261f06960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial regular grid configuration\n",
    "sim_name = \"MySim\"\n",
    "model_name = \"flow\"\n",
    "nlay = 3\n",
    "nrow = 34\n",
    "ncol = 44\n",
    "delr = delc = 1280.0\n",
    "botm = np.zeros((nlay, nrow, ncol), dtype=np.float32)\n",
    "top = np.zeros((1, nrow, ncol), dtype=np.float32)\n",
    "idom = np.ones((nlay, nrow, ncol), dtype=np.float32)\n",
    "botm[0, :, :] = 390.0\n",
    "botm[1,:,:] = 380.0\n",
    "botm[2,:,:] = -170.0\n",
    "top[0,:,:] = 460.0\n",
    "hstart = 400.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc4129-4ba2-415c-bb79-a536cc9b8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy model for a regular grid as the base grid for Gridgen\n",
    "sim = flopy.mf6.MFSimulation(sim_name=sim_name, exe_name=\"mf6\", \n",
    "                             verbosity_level=0,sim_ws=model_f)\n",
    "gwf = flopy.mf6.ModflowGwf(sim, modelname=model_name, newtonoptions=True)\n",
    "\n",
    "dis = flopy.mf6.ModflowGwfdis(\n",
    "    gwf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow,\n",
    "    ncol=ncol,\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    xorigin=729425,\n",
    "    yorigin=947000,\n",
    "    length_units='meters',\n",
    "    angrot=0,\n",
    "    idomain = idom\n",
    ")\n",
    "# export the regular grid for projection checking in a GIS suite\n",
    "dis.export(os.path.join(gis_f,'dis.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d85678-1cce-4760-b8c9-041a772388f8",
   "metadata": {},
   "source": [
    "# Run Gridgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c54d4-f610-424a-839f-d9b3a8358af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "g = Gridgen(dis)\n",
    "dam = os.path.join(gis_f,\"dam_buffer\")\n",
    "chanel = os.path.join(gis_f,\"my_channels\")\n",
    "tsf = os.path.join(gis_f,\"tsf_buffer\")\n",
    "wels = os.path.join(gis_f,\"Wells_buffered\")\n",
    "pit1500 = os.path.join(gis_f,\"pits_buffer_1500\")\n",
    "pit1000 = os.path.join(gis_f,\"pits_buffer_1000\")\n",
    "pit500 = os.path.join(gis_f,\"pits_buffer_500\")\n",
    "mod_bnd = os.path.join(gis_f,\"model_bounds\")\n",
    "act_dom = os.path.join(gis_f,\"model_bounds_poly\")\n",
    "\n",
    "g.add_refinement_features(chanel, \"line\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(wels, \"polygon\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(dam, \"polygon\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(tsf, \"polygon\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(pit1500, \"polygon\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(mod_bnd, \"line\", 3, layers=[0,1,2])\n",
    "g.add_refinement_features(pit1000, \"polygon\", 4, layers=[0,1,2])\n",
    "g.add_refinement_features(pit500, \"polygon\", 5, layers=[0,1,2])\n",
    "g.add_active_domain(act_dom,layers=[0,1,2])\n",
    "g.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6072b34-9cef-4b47-b4eb-b28238585253",
   "metadata": {},
   "source": [
    "# Copy Gridgen shapefiles to GIS for grid viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df1fea-0692-4156-8cd0-6e435f718015",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_files = [file for file in os.listdir('.') if file.startswith(\"qtgrid\")]\n",
    "for file in grd_files:\n",
    "    shutil.copyfile(file,os.path.join(gis_f,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfe786d-1be3-48b9-a12c-321dad033572",
   "metadata": {},
   "source": [
    "# Build a vertex grid object and plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0dab0-0490-45d4-8378-be872a96d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridprops_vg = g.get_gridprops_vertexgrid()\n",
    "vgrid = flopy.discretization.VertexGrid(**gridprops_vg)\n",
    "fig,ax = plt.subplots(figsize=(12,12))\n",
    "vgrid.plot(ax=ax)\n",
    "ax.set_ylabel('Northing')\n",
    "plt.title('Model Grid')\n",
    "figname = os.path.join(plots_f,'model_grid.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'model_grid.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1e0d9-cf7e-42b3-8522-db578a437aad",
   "metadata": {},
   "source": [
    "# Start the real simulation build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4ff481-cbc5-4961-9f06-b255effd0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation(sim_name=sim_name, \n",
    "                        exe_name=\"mf6\",\n",
    "                        verbosity_level=1,\n",
    "                        sim_ws=model_f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d96065-01f1-46f8-ade3-d90dbd1eca86",
   "metadata": {},
   "source": [
    "# Create the tdis object plus a timing csv\n",
    "We will use monthly stress periods during the project and then have a single recovery stress period that has monthly time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff3ae9-b5a6-4beb-8669-21b91511f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-12-31\" \n",
    "dates = pd.date_range('2023-12-31','2041-01-01', freq='MS').tolist()\n",
    "perlens = [(dates[x]-dates[x-1]).days for x in range(1,len(dates))]\n",
    "stp = 1 \n",
    "_ = [(x,stp,1) for x in perlens]\n",
    "pdata = [(1,1,1), *_, (36525, 1200, 1)] # note the recovery period here\n",
    "perlens = [x[0] for x in pdata]\n",
    "numper = len(pdata)\n",
    "\n",
    "# setting up a timing csv\n",
    "dates = [pd.to_datetime(start_date),*dates] \n",
    "# need to drop the last one. This is different to what we did previously. Why?\n",
    "df = pd.DataFrame() \n",
    "df['Date'] = dates \n",
    "df['SP'] = range(1,len(dates)+1) \n",
    "df['Flopy_SP'] = range(len(dates)) \n",
    "df['Incremental'] = perlens\n",
    "df['Cumulative'] = np.cumsum(perlens) \n",
    "df.to_csv(os.path.join(model_f,'model_timing.csv'),index=None) \n",
    "modtime_df = df.copy()\n",
    "\n",
    "tdis = flopy.mf6.ModflowTdis(sim,\n",
    "                            time_units='days',\n",
    "                            nper=numper,\n",
    "                            perioddata=pdata,\n",
    "                            start_date_time=start_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4399cd-7c22-41c4-8162-7fbcd3a37849",
   "metadata": {},
   "source": [
    "# Setup IMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb6b93-afd5-487e-8889-5fc291f6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = flopy.mf6.ModflowIms(sim, complexity='COMPLEX', \n",
    "                        csv_inner_output_filerecord='inner.csv', \n",
    "                        csv_outer_output_filerecord='outer.csv', \n",
    "                        outer_maximum=500, \n",
    "                        inner_maximum=500, \n",
    "                        outer_dvclose=0.01, \n",
    "                        inner_dvclose=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74f26f-f2f2-488c-b36d-b15ba9a76b5e",
   "metadata": {},
   "source": [
    "# Build model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33d21a-1b2b-4af9-be48-96b86c14d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwf = flopy.mf6.ModflowGwf(sim, modelname=model_name, save_flows=True, newtonoptions=\"under_relaxation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f189c02-7431-400b-a4c2-2cd33d70ae01",
   "metadata": {},
   "source": [
    "# Build the disv object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbc982-2ed2-4dd2-b8c1-4d87fcd21960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the disv grid_props\n",
    "gridprops_disv = g.get_gridprops_disv()\n",
    "\n",
    "disv = flopy.mf6.ModflowGwfdisv(gwf,angrot=0,length_units=\"METERS\", **gridprops_disv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35f8f8-007a-4a3b-9129-493fccf06ad6",
   "metadata": {},
   "source": [
    "# Cleanup Gridgen files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ae95c-52b2-4365-82c5-91dc8f53da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = os.path.join(ws8,'Gridgen')\n",
    "if os.path.exists(grid_path): \n",
    "    shutil.rmtree(grid_path)\n",
    "    os.mkdir(grid_path)\n",
    "else:\n",
    "    os.mkdir(grid_path) \n",
    "flist = [] \n",
    "for pref in ['qtg', 'quadtree', '_gridgen',]: \n",
    "    temp_list = [x for x in os.listdir() if x.startswith(pref)] \n",
    "    flist = [*flist,*temp_list] \n",
    "for file in flist:\n",
    "    shutil.move(file,grid_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f28a8-8bd2-4e29-a770-69b216c67f3a",
   "metadata": {},
   "source": [
    "# Intersect raster for model topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4907141-7491-41d2-b250-8419cb08c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_fyl = os.path.join('.','files','filled_dem.tif')\n",
    "rio1 = Raster.load(topo_fyl)\n",
    "mg=gwf.modelgrid\n",
    "top_data = rio1.resample_to_grid(mg, band=rio1.bands[0], method=\"nearest\")\n",
    "top_data[top_data>450.0]=450.0 # slicing the top elevations\n",
    "\n",
    "# Using Matplotlib subplots to create a mutiple axes figure\n",
    "fig, ax = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 1, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(8, 5), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"black\") # plot the grid on the axes using linewidths = 0.3 and black lines\n",
    "tp = pmv.plot_array(top_data, ax=ax)\n",
    "colorbar = plt.colorbar(tp, aspect=30, shrink= 0.8) # create a colorbar\n",
    "ax.set_title(f'Topography (mAMSL)')\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'topo.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'topo.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2adb0e-9fb8-431d-85be-c5b2e634897f",
   "metadata": {},
   "source": [
    "# Mapping thickness of layers using scaled range mapping\n",
    "We really don't know much about the different aquifer thickness across our model domain except that where elevation is greater the thickness is also greater. We also have some guidance on the maximum thickness of the different geological units observed by water well drillers. First we need a function to do the scale mapping for us. Then we will use our existing topography data to map thickness of our layer using the known range of maximum and minimum geological unit thickness correlated to our maximum and minimum topographic elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4193464-36f5-43bd-9e07-34b0e29b6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_me(mx1,mn1,mx2,mn2,x):\n",
    "    r1 = mx1-mn1\n",
    "    r2 = mx2-mn2\n",
    "    return((((x-mn1)*r2)/r1)+mn2)\n",
    "vf = np.vectorize(scale_me) # We vectorize the function just to make it quicker\n",
    "\n",
    "tmax = np.max(top_data)\n",
    "tmin = np.min(top_data)\n",
    "l1max = 60.0\n",
    "l1min = 30.0\n",
    "l1range = l1max-l1min\n",
    "l1_thickness = vf(tmax,tmin,l1max,l1min,top_data) # this is an array of thickness for layer 1 directly correlated with elevation\n",
    "\n",
    "l2max = 65.0\n",
    "l2min = 50.0\n",
    "l2_thickness = vf(tmax,tmin,l2max,l2min,top_data) # this is an array of thickness for layer 2 also directly correlated with elevation\n",
    "\n",
    "new_botms = np.ones_like(mg.botm)\n",
    "new_botms[0] = top_data - l1_thickness \n",
    "new_botms[1] = new_botms[0] - l2_thickness\n",
    "new_botms[2] = new_botms[1]-370.0 \n",
    "l3_thickness = new_botms[1] - new_botms[2] \n",
    "\n",
    "# assign the new elevations to the disv object and update the modelgrid\n",
    "disv.botm = new_botms\n",
    "disv.top = top_data\n",
    "mg = gwf.modelgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c806fc-57c9-4d7a-baeb-8ef5c7558022",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg.cell_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7d61f-ecd3-4449-958f-eabe03b9f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Matplotlib subplots to create a mutiple axes figure\n",
    "fig, axs = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 3, # I want three columns\n",
    "                        sharey=True, # they can share the Y-axis to save space\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(24, 8), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "for i,ax in enumerate(axs):\n",
    "    pmv = flopy.plot.PlotMapView(modelgrid=mg, layer = i, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "    pmv.plot_grid(ax=ax, lw=0.3, color=\"black\") # plot the grid on the axes using linewidths = 0.3 and black lines\n",
    "    v = pmv.plot_array(mg.cell_thickness[i], edgecolor=\"gray\", ax=ax)\n",
    "    colorbar = plt.colorbar(v, aspect=30, shrink= 0.6) # create a colorbar\n",
    "    ax.set_title(f'Thickness Model Layer {i+1}')\n",
    "    ax.set_xlabel('Eastings')\n",
    "    ax.set_ylabel('Northings')\n",
    "    ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'thickness.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'thickness.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542967e5-675a-4dbf-93ea-9e6c35ac055e",
   "metadata": {},
   "source": [
    "# Build the npf object\n",
    "Note we only need a basic object here because we will be parameterising it later and then using heterogeneity and vertical anisotropy through the prior Monte-Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482a860-40f5-4a8d-a094-58153f9221c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx_layer_prop = [1.0,1.0,0.05] # m/d \n",
    "kx_array = np.ones_like(mg.botm)\n",
    "for i,j in enumerate(kx_layer_prop):\n",
    "    kx_array[i]=j\n",
    "# Assume no anisotropy in the vertical direction\n",
    "kv_layer_prop = kx_layer_prop\n",
    "kv_array = np.ones_like(mg.botm)\n",
    "for i,j in enumerate(kv_layer_prop):\n",
    "    kv_array[i]=j\n",
    "\n",
    "npf = flopy.mf6.ModflowGwfnpf(\n",
    "    gwf,\n",
    "    xt3doptions=False,\n",
    "    pname=\"npf\",\n",
    "    save_flows=True,\n",
    "    thickstrt=True,\n",
    "    icelltype = 1,\n",
    "    k= kx_array, # ading a list of names here automatically triggers the external file\n",
    "    k33=kv_array,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64259ddc-64ac-45d6-aebd-d766f1f1b5a8",
   "metadata": {},
   "source": [
    "# Build the stor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d77d3-e3da-4d86-8186-d8584f9e80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sy_layer_prop = [0.1,0.2,0.01]\n",
    "syarray1 = np.ones_like(mg.botm)\n",
    "for i,j in enumerate(sy_layer_prop):\n",
    "    syarray1[i]=j\n",
    "ssarray1 = np.ones_like(mg.botm)*1.0E-5\n",
    "ssarray1[1] =  1.0E-6\n",
    "ssarray1[2] =  1.0E-7\n",
    "ictype = np.ones_like(mg.botm)\n",
    "ictype[0] = 1\n",
    "ictype[1] = 1\n",
    "\n",
    "sto = flopy.mf6.ModflowGwfsto(\n",
    "    gwf,\n",
    "    pname=\"sto\",\n",
    "    save_flows=True,\n",
    "    iconvert=ictype,\n",
    "    ss=ssarray1,\n",
    "    sy=syarray1,\n",
    "    steady_state={0: True},\n",
    "    transient={1: True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505de825-dd2c-4f32-8a41-b5ebe26e83f5",
   "metadata": {},
   "source": [
    "# Configure boundaries\n",
    "Now we are going to use intersection cell selection to help setup our boundary conditions but first we need a function to help expidite the intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff4ac4-9e0e-485b-afbc-3ef6aa7dee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def get_bnodes(shpfyl): # works with single and multiple line strings\n",
    "    ix = GridIntersect(mg, method=\"vertex\")\n",
    "    poly = gpd.read_file(shpfyl).geometry\n",
    "    if len(poly)==1:\n",
    "        return(ix.intersect(poly[0]).cellids)\n",
    "    else:\n",
    "        ls = []\n",
    "        for item in poly:\n",
    "            nums = ix.intersect(item).cellids\n",
    "            ls = [*ls,*nums]\n",
    "        return(np.asarray(ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033c34c-6ece-4bb2-8791-6deaca1a2aa4",
   "metadata": {},
   "source": [
    "# Creating cell selection groups for use in boundary configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4047598-0ed4-4fce-9f1d-c57cb9323258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get our boundary cells into groups we already have chanel, and mod_bnd loaded from gridgen\n",
    "# but we will add then again here just for completness\n",
    "chanel = os.path.join(gis_f,\"my_channels.shp\")\n",
    "ghb_north = os.path.join(gis_f,\"ghb_north.shp\")\n",
    "ghb_south = os.path.join(gis_f,\"ghb_south.shp\")\n",
    "lamarahoue = os.path.join(gis_f,\"La_Marahoue_river_boundary.shp\")\n",
    "bandamrouge = os.path.join(gis_f,\"Bandam_Rouge_river_boundary.shp\")\n",
    "yani = os.path.join(gis_f,\"Yani_river_boundary.shp\")\n",
    "grid = os.path.join(gis_f,\"qtgrid.shp\")\n",
    "wels = os.path.join(gis_f,\"dewatering_wells.shp\")\n",
    "\n",
    "yani_nodes = get_bnodes(yani)\n",
    "bandamrouge_nodes = get_bnodes(bandamrouge)\n",
    "lamarahoue_nodes = get_bnodes(lamarahoue)\n",
    "ghb_south_nodes = get_bnodes(ghb_south)\n",
    "ghb_north_nodes = get_bnodes(ghb_north)\n",
    "chanel_nodes = get_bnodes(chanel)\n",
    "well_nodes = get_bnodes(wels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d79e24-a94a-41e4-91a3-32fbc209dfb7",
   "metadata": {},
   "source": [
    "# Setup a GHB to the North\n",
    "Here too we are making an assumption about the hydraulic heads along this boundary. In this case we assume a subdued replica of the topography because we know that topography has a strong control on water table elevation due to very low K of the surficial aquifer. Nevertheless the boundary is situated sufficiently far enough away from the project site that it won't impact our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa1149-bbbd-4826-a38a-918ac48494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = [mg.top[x] for x in ghb_north_nodes]\n",
    "max = np.max(topo)\n",
    "max_id = topo.index(max)\n",
    "# okay so now we need to split the boundary into two different ranges\n",
    "range1 = topo[0:max_id+1]\n",
    "range2 = topo[max_id+1:]\n",
    "# now we create our heads for range1\n",
    "r1min = np.min(range1)\n",
    "r1max = max\n",
    "dtw_min = 2.0\n",
    "dtw_max = 40.0\n",
    "r1_dtw = vf(r1max,r1min,dtw_max,dtw_min,range1)\n",
    "r1heads = range1-r1_dtw\n",
    "# repeat for range2\n",
    "r2min = np.min(range2)\n",
    "r2max = max\n",
    "dtw_min = 2.0\n",
    "dtw_max = 40.0\n",
    "r2_dtw = vf(r2max,r2min,dtw_max,dtw_min,range2)\n",
    "r2heads = range2-r2_dtw\n",
    "# now unpack into a new list \n",
    "ghb_north_heads = [*r1heads,*r2heads]*3 # will need to repeat for three layers\n",
    "\n",
    "node_tups = [(i,j) for i in range(3) for j in ghb_north_nodes]\n",
    "ghb1_pdata = [(item,ghb_north_heads[i],mg.cell_thickness[item[0]][item[1]]*kx_layer_prop[item[0]],'ghb1') for i,item in enumerate(node_tups)]\n",
    "ghb1_period={}\n",
    "ghb1_period[0] = ghb1_pdata\n",
    "ghb1 = flopy.mf6.ModflowGwfghb(gwf,boundnames=True,save_flows=True, maxbound=len(ghb1_pdata),\\\n",
    "                            stress_period_data=ghb1_period,pname='ghb1',\n",
    "                            filename=\"{}_1.ghb\".format(model_name),)\n",
    "\n",
    "# Setup obs arrays for ghb\n",
    "obs1_recarray = {\n",
    "    \"ghb1_obs.csv\": [\n",
    "        (\"ghb1\", \"GHB\", 'ghb1')]\n",
    "}\n",
    "ghb1.obs.initialize(\n",
    "    filename=\"{}_1.ghb.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs1_recarray,\n",
    ")\n",
    "\n",
    "# plot the assumed heads and topography along the boundary\n",
    "# each point approximateley 320 meters apart \n",
    "x = np.cumsum([320.0]*len(ghb_north_nodes))\n",
    "y = topo\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "ax.plot(x,y,label=\"topography\")\n",
    "ax.plot(x,ghb_north_heads[:len(ghb_north_nodes)],label='heads')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1558e-af2a-4034-9d54-6421dc8107fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 1, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(8, 5), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"grey\", alpha=0.3) # plot the grid on the axes using linewidths = 0.3 and grey lines\n",
    "pmv.plot_bc(name='ghb1',package=ghb1)\n",
    "ax.set_title('GHB Cells North')\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'ghb_north.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'ghb_north.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7ec76-2dc7-4560-a915-2d623b9017e4",
   "metadata": {},
   "source": [
    "# Setup a GHB to the South using the same method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e714e-defe-44dd-99eb-3b10f173ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = [mg.top[x] for x in ghb_south_nodes]\n",
    "max = np.max(topo)\n",
    "max_id = topo.index(max)\n",
    "# okay so now we need to split the boundary into two different ranges\n",
    "range1 = topo[0:max_id+1]\n",
    "range2 = topo[max_id+1:]\n",
    "# now we create our heads for range1\n",
    "r1min = np.min(range1)\n",
    "r1max = max\n",
    "dtw_min = 2.0\n",
    "dtw_max = 30.0\n",
    "r1_dtw = vf(r1max,r1min,dtw_max,dtw_min,range1)\n",
    "r1heads = range1-r1_dtw\n",
    "# repeat for range2\n",
    "r2min = np.min(range2)\n",
    "r2max = max\n",
    "dtw_min = 2.0\n",
    "dtw_max = 30.0\n",
    "r2_dtw = vf(r2max,r2min,dtw_max,dtw_min,range2)\n",
    "r2heads = range2-r2_dtw\n",
    "# now unpack into a new list \n",
    "ghb_south_heads = [*r1heads,*r2heads]*3 # will need to repeat for three layers\n",
    "\n",
    "# now we can start building our boundary condition\n",
    "node_tups = [(i,j) for i in range(3) for j in ghb_south_nodes]\n",
    "ghb2_pdata = [(item,ghb_south_heads[i],mg.cell_thickness[item[0]][item[1]]*kx_layer_prop[item[0]],'ghb2') for i,item in enumerate(node_tups)]\n",
    "ghb2_period={}\n",
    "ghb2_period[0] = ghb2_pdata\n",
    "ghb2 = flopy.mf6.ModflowGwfghb(gwf,boundnames=True,save_flows=True, maxbound=len(ghb2_pdata),\\\n",
    "                            stress_period_data=ghb2_period,pname='ghb2',\n",
    "                            filename=\"{}_2.ghb\".format(model_name),)\n",
    "\n",
    "# Setup obs arrays for drn\n",
    "obs2_recarray = {\n",
    "    \"ghb2_obs.csv\": [\n",
    "        (\"ghb2\", \"GHB\", \"ghb2\")]\n",
    "}\n",
    "ghb2.obs.initialize(\n",
    "    filename=\"{}_2.ghb.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs2_recarray,\n",
    ")\n",
    "\n",
    "# plot the result to have a look at it\n",
    "# each point is approximateley 320 meters apart\n",
    "x = np.cumsum([320.0]*len(ghb_south_nodes))\n",
    "y = topo\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "ax.plot(x,y,label=\"topography\")\n",
    "ax.plot(x,ghb_south_heads[:len(ghb_south_nodes)],label='heads')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462961b7-69c9-4722-83b1-97b0f2339d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 1, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(8, 5), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"grey\", alpha=0.3) # plot the grid on the axes using linewidths = 0.3 and grey lines\n",
    "pmv.plot_bc(name='ghb1',package=ghb2)\n",
    "ax.set_title('GHB Cells South')\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'ghb_south.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'ghb_south.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367cb47-a8f0-4842-9774-68bbb468f254",
   "metadata": {},
   "source": [
    "# Configure drain packages for rivers and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e0bf1-07fa-4f1d-ac89-c26a1735d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# River and chanel drain boundaries should be a bit easier \n",
    "# because we will just assume drain elevation is about 1m below topography\n",
    "# Lets start with the drains for the Yani. Recall we only need these in layer 1\n",
    "lay = 0\n",
    "# river is not full width of cell\n",
    "# assume width of river is 20 m x cell length 320 m gives\n",
    "a = 20*320\n",
    "# initial conductance estimate is K*A\n",
    "cond0 = kx_layer_prop[0]*a\n",
    "drn1_pdata = [((lay,node),mg.top[node]-1,cond0,\"yani\") for node in yani_nodes]\n",
    "drn1_period={}\n",
    "drn1_period[0]=drn1_pdata\n",
    "drn1 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=len(drn1_pdata),\\\n",
    "                            stress_period_data=drn1_period,pname='drn1',\n",
    "                            filename=\"{}_1.drn\".format(model_name),)\n",
    "# Setup obs arrays for drn\n",
    "obs3_recarray = {\n",
    "    \"drn_yani_obs.csv\": [\n",
    "        (\"drn1\", \"DRN\", \"yani\")]\n",
    "}\n",
    "drn1.obs.initialize(\n",
    "    filename=\"{}_1.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs3_recarray,\n",
    ")\n",
    "\n",
    "drn2_pdata = [((lay,node),mg.top[node]-1,cond0,\"lamarahoue\") for node in lamarahoue_nodes]\n",
    "drn2_period={}\n",
    "drn2_period[0]=drn2_pdata\n",
    "drn2 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=len(drn2_pdata),\\\n",
    "                            stress_period_data=drn2_period,pname='drn2',\n",
    "                            filename=\"{}_2.drn\".format(model_name),)\n",
    "# Setup obs arrays for drn\n",
    "obs4_recarray = {\n",
    "    \"drn_lamarahoue_obs.csv\": [\n",
    "        (\"drn2\", \"DRN\", \"lamarahoue\")]\n",
    "}\n",
    "drn2.obs.initialize(\n",
    "    filename=\"{}_2.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs4_recarray,\n",
    ")\n",
    "\n",
    "drn3_pdata = [((lay,node),mg.top[node]-1,cond0,\"bandamrouge\") for node in bandamrouge_nodes]\n",
    "drn3_period={}\n",
    "drn3_period[0]=drn3_pdata\n",
    "drn3 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=len(drn3_pdata),\\\n",
    "                            stress_period_data=drn3_period,pname='drn3',\n",
    "                            filename=\"{}_3.drn\".format(model_name),)\n",
    "# Setup obs arrays for drn\n",
    "obs5_recarray = {\n",
    "    \"drn_bandamrouge_obs.csv\": [\n",
    "        (\"drn3\", \"DRN\", \"bandamrouge\")]\n",
    "}\n",
    "drn3.obs.initialize(\n",
    "    filename=\"{}_3.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs5_recarray,\n",
    ")\n",
    "\n",
    "drn4_pdata = [((lay,node),mg.top[node]-0.5,cond0,\"channel\") for node in chanel_nodes]\n",
    "drn4_period={}\n",
    "drn4_period[0]=drn4_pdata\n",
    "drn4 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=len(drn4_pdata),\\\n",
    "                            stress_period_data=drn4_period,pname='drn4',\n",
    "                            filename=\"{}_4.drn\".format(model_name),)\n",
    "# Setup obs arrays for drn\n",
    "obs6_recarray = {\n",
    "    \"drn_channel_obs.csv\": [\n",
    "        (\"drn4\", \"DRN\", \"channel\")]\n",
    "}\n",
    "drn4.obs.initialize(\n",
    "    filename=\"{}_4.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs6_recarray,\n",
    ")\n",
    "\n",
    "drn_obj_ls = [drn1,drn2,drn3,drn4] # make a list of our drain objects\n",
    "panms = [\"yani\",\"lamarahoue\",\"bandamrouge\",\"channel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b754f-0d8e-4b36-b2f7-ff617b0c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 2, # I want one row\n",
    "                        ncols = 2, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(14, 11), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "for ax,pak,nam in zip(axs.flatten(),drn_obj_ls,panms):\n",
    "    pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "    pmv.plot_grid(ax=ax, lw=0.3, color=\"grey\", alpha=0.3) # plot the grid on the axes using linewidths = 0.3 and grey lines\n",
    "    pmv.plot_bc(package=pak, color='red')\n",
    "    ax.set_title(f'{nam} cells')\n",
    "    ax.set_xlabel('Eastings')\n",
    "    ax.set_ylabel('Northings')\n",
    "    ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'Rivers_and_channels.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'Rivers_and_channels.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fe107-8558-47ee-9244-d8be6c1e4ead",
   "metadata": {},
   "source": [
    "# Mining simulation South Pit\n",
    "There are two mining pits planned for the project location called the South Pit and North Pit. We will configure some cascading drains to implicitly represent the mining process and the dewater that is likely to accompany it. We start by creating groups of the model cells within the mine pits in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3124daa-8121-4dd0-9238-308344ea38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add the drains for the mine pit simualtions\n",
    "spit = os.path.join(gis_f,\"spit_outer_poly.shp\")\n",
    "npit = os.path.join(gis_f,\"npit_outer_poly.shp\")\n",
    "spit_nodes = get_bnodes(spit)\n",
    "npit_nodes = get_bnodes(npit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2b383-e23a-4971-addd-de6f2ff575c4",
   "metadata": {},
   "source": [
    "Then we map elevations of the pit shell to an array like Layer 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9904bd-925f-46b7-9823-b2a3c19e2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "spit_shell = os.path.join(gis_f,'SouthPitShell.tif')\n",
    "rio = Raster.load(spit_shell)\n",
    "spit_data = rio.resample_to_grid(\n",
    "    mg, band=rio.bands[0], method=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4809c-95ba-41b2-a372-f1d85af20255",
   "metadata": {},
   "source": [
    "Then we get the elevations of the mapped cells in the pit only. Find the value lowest elevation, which is the deepest part of the pit. Then find that locations array index. then get the model top elevations without the pit shell and find the maximum vertical distance that we may need to cascade our drains along. This will allow us to develop a descending rate that we can use to move our drain cells downwards to mimic the mining operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee42469-bbea-49a5-a7f6-c46809de6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdepths = spit_data[spit_nodes.astype('int')]\n",
    "pit_min = sdepths.min()\n",
    "# get index of pit_min\n",
    "id = np.where(sdepths==pit_min)[0]\n",
    "tops = [mg.top[spit_nodes[x]] for x in id]\n",
    "distance = top.max()-pit_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a07600-4b6a-4a89-8a3b-cbd80119c219",
   "metadata": {},
   "source": [
    "The mining process will last 9 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bae6b-410b-4a02-9af7-668fddd2fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtime = 365*9\n",
    "mrate = distance/mtime\n",
    "print(distance)\n",
    "print(f'drain descending rate = {mrate} m/d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4a4cc-61cb-464b-a51a-f6f19a7200a9",
   "metadata": {},
   "source": [
    "Now mining in the South Pit will start one year after the project commences. Recall that the steady-state stress period is stress period 1 (or 0 in Flopy). Therefore stress period 2 to stress period 13 won't have any mining and we need to start our cascade of drains in stress period 14. The algorithm that builds the cascade follows. It is working out the elevation that each drain boundary condition will be staring in layer one. If a drain boundary needs to turn on in layer 2 then the descending drain in layer one is set to the base of layer 1 and stays there while the drain in layer 2 keeps moving downwards. This sequence continues until the pit shell depth is reached where the drain halts and holds position until deactivated. We will be populating a stress period dictionary for use with the drain package. See if you can follow along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216249d-51ad-47cb-bc6d-de1a4b55bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = {key:[] for key in range(len(perlens)+1)} # steting up a dictionary keyed to stress period numbers with empty lists\n",
    "cond = [100.0,100.0,100.0] # need one for each layer\n",
    "cu_time = np.cumsum(perlens[12:]) # getting a cumulative count of time from the start of mining\n",
    "nam = 'southpit' # setting a name for the boundary\n",
    "\n",
    "for dnode,sd in zip(spit_nodes,sdepths): \n",
    "    st = mg.top[dnode] # this is the surface elevation of the node in the pit\n",
    "    for i in range(len(perlens[12:])): # For each stress period \n",
    "        tm = cu_time[i] # get the total time elapsed since start of mine\n",
    "        drop = mrate*tm # work out the estimated descent \n",
    "        new_ev = st-drop # what elevation are we at now\n",
    "        sp = i+1+12 # this si the stress period number used as a key for the dictionary +1 for the SS period, + 12 for the first year of no mining\n",
    "        for j in range(nlay): # for each layer we will test if we are above or below. Break statements will prevent mutiple assigmnments.\n",
    "            t_ev= mg.botm[j][dnode] # get the botom of the layer so we can test against it\n",
    "            if new_ev>t_ev: # are we above this test elevation\n",
    "                if new_ev<sd: # test if we are further than the planned excavtion elevation\n",
    "                    t_dict[sp].append(((j,dnode),sd,cond[j],nam)) # if we are then set a drain at the stop depth\n",
    "                    break # jumps out of this for loop\n",
    "                else:\n",
    "                    t_dict[sp].append(((j,dnode),new_ev,cond[j],nam)) # if we are above the layer bottom but havent exceeded stop depth set a drain at the new elevation\n",
    "                    break # jumps out of this for loop since we are above this test elevation and haven't past stop depth we don't need to enter anymore drains for this period\n",
    "            elif (sd>t_ev): # test if we are further than the planned excavtion elevation and below the layer\n",
    "                    t_dict[sp].append(((j,dnode),sd,cond[j],nam)) # if we are then set a drain at the stop depth                    \n",
    "                    break # jumps out of this for loop since we are at stop depth\n",
    "            else: # if we are below the test elevation set a drain at the test elevation or stop depth if bottom of mine\n",
    "                t_dict[sp].append(((j,dnode),t_ev,cond[j],nam))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b3a14-72a2-44c6-b523-0456d30a996d",
   "metadata": {},
   "source": [
    "Mining needs to stop after nine years but we also have a year at the start of the model with no mining plus a steady-state stress period. So we need to set a time to stop mining where all drains in the mine pits turn off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2b372-e498-42d5-a484-604cdb120a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_mine = (12*9)+12+1 # added 12 on for the first year of no mining\n",
    "for i in range(stop_mine,numper):\n",
    "    t_dict[i]=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ae367-f9ed-4ac6-ac83-59657f694c1c",
   "metadata": {},
   "source": [
    "We need a value for the maxbound variable in the drain package because the number of drains will vary in each stress period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c64b2-1ce4-41d0-9fbe-5b90b7a20b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get the value for maxbound from the t_dict we just created\n",
    "_ = [len(t_dict[key]) for key in t_dict.keys()]\n",
    "mxbnd = np.max(_)\n",
    "print(mxbnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e4c86-a665-411c-bdf2-e5e3fbddee24",
   "metadata": {},
   "source": [
    "Now we can build our drain package for the South Pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c204b1-96a8-4800-a7e9-3f2157e27b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drn5 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=mxbnd,\\\n",
    "                               stress_period_data=t_dict,pname=nam,\n",
    "                               filename=\"{}_5.drn\".format(model_name))\n",
    "# Setup obs arrays for drn\n",
    "obs7_recarray = {\n",
    "    \"drn_southpit_obs.csv\": [\n",
    "        (\"southpit\", \"DRN\", \"southpit\")]\n",
    "}\n",
    "drn5.obs.initialize(\n",
    "    filename=\"{}_5.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs7_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a05f8-dfff-4a4f-8123-74e853e69de4",
   "metadata": {},
   "source": [
    "To view the boundary cells without seeing the entire grid we need to zoom in on the axes of the plot. We do this using a shapefile of the pits buffered out 1500 m. With some Geopandas magic we can get the extents of the shapefile and use them as our axes limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1019cf8-c173-41d9-8f2d-9a48a638c7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pit1500 = os.path.join(gis_f,\"pits_buffer_1500.shp\")\n",
    "gdf1 = gpd.read_file(pit1500)\n",
    "gdf1.set_crs(epsg=32629)\n",
    "extents = gdf1.geometry.total_bounds\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 1, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(8, 5), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"grey\", alpha=0.3) # plot the grid on the axes using linewidths = 0.3 and grey lines\n",
    "pmv.plot_bc(name='southpit',package=drn5,kper=13, color='red') # note how you also need to select the period where the bounadry is active or it won't plot.\n",
    "ax.set_title('DRN Cells South Pit')\n",
    "ax.set_xlim(extents[0],extents[2])\n",
    "ax.set_ylim(extents[1],extents[3])\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'drn_south_pit.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'drn_south_pit.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab282555-6ea8-4e7c-9e63-c1556a1908f8",
   "metadata": {},
   "source": [
    "After mining the pits will be backfilled with tailings as a slurry. The levels of the tailings plus the estimated water levels above the tailing were obtained from a tailings dam model. We will use this information to build a constant head boundary with time series to simulate the planned backfill. We read the information in from a csv to begin with then setup the constant head boundary to be active until the end of the planned backfill operation at which time the constant head boundary will be deactivated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28839c1-5a4f-444e-a830-e0604670a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fyl = os.path.join(gis_f, \"spit_level.csv\")\n",
    "df = pd.read_csv(fyl)\n",
    "temp = [x-df.loc[0,'Year'] for x in df['Year']]\n",
    "df['sp'] = [(stop_mine)+ (x*12) for x in temp] # this gives me the stress period numbers that line up with the years\n",
    "\n",
    "\n",
    "df.index = df['sp'] # we make the stress period numbers the index\n",
    "tdf = pd.DataFrame(index=range(df.index[0],df.index[-1]+1)) # make a new dataframe with an index that includes all stress periods inbetween\n",
    "tdf['sp'] = tdf.index # make a stress period column, not entireley necessary but we will use it later\n",
    "# Now make an nan entry in each column if we don't have a defined value from original dataframe \n",
    "tdf['Year'] = [np.nan if not x in df['sp'] else df.loc[x,'Year'] for x in tdf.index] \n",
    "tdf['level'] = [np.nan if not x in df['sp'] else df.loc[x,'level'] for x in tdf.index]\n",
    "tdf = tdf.interpolate()\n",
    "tdf.to_csv('test.csv')\n",
    "chd_pdata={}\n",
    "for sp,levl in zip(tdf['sp'],tdf['level']): \n",
    "    tlist = spit_nodes.astype(\"int\").tolist()\n",
    "    pdata =[]\n",
    "    for lay in range(nlay):\n",
    "        for node in tlist:\n",
    "            if levl>mg.botm[lay,node]:\n",
    "                pdata.append(((lay,node),'level','backfill')) # using a timeseries name here\n",
    "                tlist.remove(node)\n",
    "    chd_pdata[sp]=pdata\n",
    "# now add on a final stress period with no chd nodes to make sure everything goes back to active cells\n",
    "chd_pdata[sp+1] = []\n",
    "\n",
    "chd1 = flopy.mf6.ModflowGwfchd(gwf, boundnames=True, save_flows=True, maxbound=len(spit_nodes),\n",
    "                               stress_period_data=chd_pdata,\n",
    "                               filename=\"{}_1.chd\".format(model_name), pname='chd1')\n",
    "\n",
    "# make the tsdata\n",
    "model_time = np.cumsum(tdis.perioddata.array['perlen'])\n",
    "sptime = model_time[-1] # model run time in days at end of model run\n",
    "ts_data = [(model_time[x-1],tdf.loc[x,'level']) for x in tdf.index] # note you must have this start at t=1.0 and end at the end of the model run\n",
    "ts_data = [(1.0,ts_data[0][1]),*ts_data,(sptime,ts_data[-1][1])]\n",
    "# the time series is only effective from stop_mine because that is when the tvk package activates so\n",
    "\n",
    "# initialize first time series\n",
    "chd1.ts.initialize(\n",
    "    filename=\"chd1.ts\",\n",
    "    timeseries=ts_data,\n",
    "    time_series_namerecord=['level'],\n",
    "    interpolation_methodrecord=[\"linear\"],\n",
    ")\n",
    "\n",
    "# setup the observations\n",
    "# Setup obs arrays for drn\n",
    "obs11_recarray = {\n",
    "    \"chd_backfill_obs.csv\": [\n",
    "        (\"backfill\", \"CHD\", \"backfill\")]\n",
    "}\n",
    "chd1.obs.initialize(\n",
    "    filename=\"{}_1.chd.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs11_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540db4b-b649-42f4-94c3-079653dcd123",
   "metadata": {},
   "source": [
    "# Mining in the North Pit\n",
    "The mining process is simulated in a similar manner however the timings are a bit different and there is no backfill of tailings planned for the North Pit but instead it will be filled with waste rock from the mining process. The process of building the cascading drains ai the same. starting with the pit shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da789d4-e2c2-4b42-9659-028f401dda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "npit_shell = os.path.join(gis_f,'NorthPitShell.tif')\n",
    "rio = Raster.load(npit_shell)\n",
    "npit_data = rio.resample_to_grid(\n",
    "    mg, band=rio.bands[0], method=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364977f3-d255-4ee1-b7f3-1993ba594a5f",
   "metadata": {},
   "source": [
    "The depths are different and the timing is different so we need a different mining rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506256b-7b2d-4216-a00b-35ef855ec435",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndepths = npit_data[npit_nodes.astype('int')]\n",
    "pit_min = ndepths.min()\n",
    "# get index of pit_min\n",
    "id = np.where(ndepths==pit_min)[0]\n",
    "tops = [mg.top[spit_nodes[x]] for x in id]\n",
    "distance = top.max()-pit_min\n",
    "# assume north pit dewaters to base in 3 years \n",
    "mtime = 365*3\n",
    "mrate = distance/mtime\n",
    "print(distance)\n",
    "print(f'drain descending rate = {mrate} m/d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96383d50-4c33-47a3-9261-25424af23b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_period = 47 +12\n",
    "t_dict = {key:[] for key in range(start_period,len(perlens)+1)} # only starts mining in year 4.\n",
    "cond = [100.0,100.0,100.0] # need one for each layer\n",
    "cu_time = np.cumsum(perlens[12:])\n",
    "nam = 'northpit'\n",
    "\n",
    "for dnode,sd in zip(npit_nodes,ndepths): \n",
    "    st = mg.top[dnode] # this is the surface elevation of the node in the pit\n",
    "    for i in range(start_period,len(perlens[12:])): # For each stress period\n",
    "        tm = cu_time[i]-cu_time[start_period]# get the total time elapsed since start of mine\n",
    "        drop = mrate*tm # work out the estimated descent \n",
    "        new_ev = st-drop # what elevation are we at now\n",
    "        sp = i # this si the stress period number used as a key for the dictionary +1 for the SS period, + 12 for the first year of no mining\n",
    "        for j in range(nlay): # for each layer we will test if we are above or below. Break statements will prevent mutiple assigmnments.\n",
    "            t_ev= mg.botm[j][dnode] # get the botom of the layer so we can test against it\n",
    "            if new_ev>t_ev: # are we above this test elevation\n",
    "                if new_ev<sd: # test if we are further than the planned excavtion elevation\n",
    "                    t_dict[sp].append(((j,dnode),sd,cond[j],nam)) # if we are then set a drain at the stop depth\n",
    "                    break # jumps out of this for loop\n",
    "                else:\n",
    "                    t_dict[sp].append(((j,dnode),new_ev,cond[j],nam)) # if we are above the layer bottom but havent exceeded stop depth set a drain at the new elevation\n",
    "                    break # jumps out of this for loop since we are above this test elevation and haven't past stop depth we don't need to enter anymore drains for this period\n",
    "            elif (sd>t_ev): # test if we are further than the planned excavtion elevation and below the layer\n",
    "                    t_dict[sp].append(((j,dnode),sd,cond[j],nam)) # if we are then set a drain at the stop depth                    \n",
    "                    break # jumps out of this for loop since we are at stop depth\n",
    "            else: # if we are below the test elevation set a drain at the test elevation or stop depth if bottom of mine\n",
    "                t_dict[sp].append(((j,dnode),t_ev,cond[j],nam))\n",
    "\n",
    "# Note mining turns off at the end of year 9 which is (12*9)+1 stress periods\n",
    "stop_mine = (12*9)+12+1# +1 for SS then + 12 for the firsa year of no mining\n",
    "for i in range(stop_mine,numper):\n",
    "    t_dict[i]=[]\n",
    "\n",
    "# we need to get the value for maxbound from the t_dict we just created\n",
    "test = [len(t_dict[key]) for key in t_dict.keys()]\n",
    "mxbnd = np.max(test)\n",
    "print(mxbnd)\n",
    "\n",
    "# Now we build the new drain package for the main pit\n",
    "drn6 = flopy.mf6.ModflowGwfdrn(gwf,boundnames=True,save_flows=True, maxbound=mxbnd,\\\n",
    "                               stress_period_data=t_dict,pname=nam,\n",
    "                               filename=\"{}_6.drn\".format(model_name))\n",
    "# Setup obs arrays for drn\n",
    "obs8_recarray = {\n",
    "    \"drn_northpit_obs.csv\": [\n",
    "        (\"northpit\", \"DRN\", \"northpit\")]\n",
    "}\n",
    "drn6.obs.initialize(\n",
    "    filename=\"{}_6.drn.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs8_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f3550-cab1-432a-b43b-0fcc2f7890f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, # I want one row\n",
    "                        ncols = 1, # I want three columns\n",
    "                        subplot_kw={'aspect':'equal'}, # Each sub_plot must have aspect = equal to keep x and y ratios consistent\n",
    "                        figsize=(8, 5), # setting figure size Note had to increase the x dimension here\n",
    "                        constrained_layout=True)\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mg, ax=ax) #creating a mapview object assigning a specific layer and specifying the axes\n",
    "pmv.plot_grid(ax=ax, lw=0.3, color=\"grey\", alpha=0.3) # plot the grid on the axes using linewidths = 0.3 and grey lines\n",
    "pmv.plot_bc(name='northpit',package=drn6,kper=60, color='red') # note how you also need to select the period where the bounadry is active or it won't plot.\n",
    "ax.set_title('DRN Cells North Pit')\n",
    "ax.set_xlim(extents[0],extents[2])\n",
    "ax.set_ylim(extents[1],extents[3])\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "figname = os.path.join(plots_f,'drn_north_pit.png') \n",
    "fig.savefig(figname,dpi=300)\n",
    "figname = os.path.join(plots_f,'drn_north_pit.pdf')\n",
    "fig.savefig(figname,dpi=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686628ea-c92e-41aa-ab7b-798d1e61a600",
   "metadata": {},
   "source": [
    "# Transient properties\n",
    "To account for the likely change in properties of the aquifers after backfill and waste rock plus consolidation over time we will use transient properties. Note the representative values that are assigned here initially are rough estimates. They are explored in more detail during the Monte-Carlo of the prior. You can only have one TVK and TVS package assigned to a model but we can have multiple time series. For now we will use the same time series for both North and South Pits. We start with TVK and follow with TVS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ab09b-aaa9-4e0c-aa14-5458e9dd144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for lay in range(nlay):\n",
    "    for node in spit_nodes.astype(\"int\"):\n",
    "        pdata.append(((lay,node),'k','spitk'))\n",
    "        pdata.append(((lay,node),'k33','spitk33'))\n",
    "    for node in npit_nodes.astype(\"int\"):\n",
    "        pdata.append(((lay,node),'k','npitk'))\n",
    "        pdata.append(((lay,node),'k33','npitk33'))\n",
    "\n",
    "\n",
    "tvk_pdata = {}\n",
    "for key in range(stop_mine,numper):\n",
    "    tvk_pdata[key] = pdata\n",
    "tvk = flopy.mf6.ModflowUtltvk(npf,perioddata=tvk_pdata,\n",
    "                               filename=\"{}.tvk\".format(model_name))\n",
    "\n",
    "# make the tsdata\n",
    "model_time = np.cumsum(tdis.perioddata.array['perlen'])\n",
    "stime = model_time[stop_mine-1] # model run time in days at stop_mine\n",
    "sptime = model_time[-1] # model run time in days at end of model run\n",
    "ts_data = [(1.0,10.0,10.0,10.0,10.0),(stime,10.0,10.0,10.0,10.0),(sptime,1.0,1.0,1.0,1.0)] # note you must have this start at t=1.0 and end at the end of the model run\n",
    "# the time series is only effective from stop_mine because that is when the tvk package activates so\n",
    "\n",
    "# initialize first time series\n",
    "tvk.ts.initialize(\n",
    "    filename=\"tvk.ts\",\n",
    "    timeseries=ts_data,\n",
    "    time_series_namerecord=[\"spitk\",\"spitk33\",\"npitk\",\"npitk33\"],\n",
    "    interpolation_methodrecord=[\"linear\",\"linear\",\"linear\",\"linear\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034438a6-ec6e-49a7-9075-028b81624275",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=[]\n",
    "for lay in range(nlay):\n",
    "    for node in spit_nodes.astype(\"int\"):\n",
    "        pdata.append(((lay,node),'sy','spitsy'))\n",
    "        pdata.append(((lay,node),'ss','spitss'))\n",
    "    for node in npit_nodes.astype(\"int\"):\n",
    "        pdata.append(((lay,node),'sy','npitsy'))\n",
    "        pdata.append(((lay,node),'ss','npitss'))\n",
    "\n",
    "tvs_pdata = {}\n",
    "for key in range(stop_mine,numper):\n",
    "    tvs_pdata[key] = pdata\n",
    "tvs = flopy.mf6.ModflowUtltvs(sto,perioddata=tvs_pdata,\n",
    "                               filename=\"{}.tvs\".format(model_name))\n",
    "\n",
    "# make the tsdata\n",
    "model_time = np.cumsum(tdis.perioddata.array['perlen'])\n",
    "stime = model_time[stop_mine-1] # model run time in days at stop_mine\n",
    "sptime = model_time[-1] # model run time in days at end of model run\n",
    "ts_data = [(1.0,0.3,1.0E-04,0.3,1.0E-04),(stime,0.3,1.0E-04,0.3,1.0E-04),(sptime,0.05,1.0E-06,0.05,1.0E-06)] # note you must have this start at t=1.0 and end at the end of the model run\n",
    "# the time series is only effective from stop_mine because that is when the tvk package activates so\n",
    "\n",
    "# initialize first time series\n",
    "tvs.ts.initialize(\n",
    "    filename=\"tvs.ts\",\n",
    "    timeseries=ts_data,\n",
    "    time_series_namerecord=['spitsy','spitss','npitsy','npitss'],\n",
    "    interpolation_methodrecord=[\"linear\",\"linear\",\"linear\",\"linear\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aac3fd-6113-4f27-bef5-8e9af102af4f",
   "metadata": {},
   "source": [
    "# Recharge \n",
    "There is an annual mean of 1212 mm rainfall. We know recharge is small at between 0.5 % and 2 % rainfall given previous investigations. We will setup a recharge package with a preferred value which is central to the log transformed expected recharge range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643e158-02da-414a-94d5-4088928fc3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_rate = 1220/365/1000 # (m/d)\n",
    "min_rate = 0.005*rain_rate\n",
    "max_rate = 0.03*rain_rate\n",
    "# our preferred value which is central to log of min and max\n",
    "pv =  10**(np.log10(min_rate)+((np.log10(max_rate)-np.log10(min_rate))/2)) \n",
    "\n",
    "# we also want to enhance recharge after the tailings deposition stops which is in stress period 194 (zero base)\n",
    "# so we ned an array of multipliers 1.33 increase recharge by 1/3 in the south pit only\n",
    "rch_mult_array=np.ones_like(mg.top)\n",
    "rch_mult_array[spit_nodes.astype('int')]=1.33\n",
    "\n",
    "\n",
    "rch_array_0=np.ones_like(mg.top)*pv\n",
    "rch_period = {}\n",
    "rch_period[0]=rch_array_0\n",
    "rch_period[194] = rch_array_0\n",
    "aux_period = {}\n",
    "aux_period[0]=[np.ones_like(mg.top)] # note these have to be lists with a number of arrays equal to the the number of auxiliary variables\n",
    "aux_period[194] = [rch_mult_array]  # note these have to be lists with a number of arrays equal to the the number of auxiliary variables\n",
    "\n",
    "rch = flopy.mf6.ModflowGwfrcha(\n",
    "    gwf,\n",
    "    filename=\"{}.rch\".format(model_name),\n",
    "    pname=\"rch\",\n",
    "    fixed_cell=True,\n",
    "    save_flows=True,\n",
    "    recharge=rch_period,\n",
    "    auxiliary='pit',\n",
    "    auxmultname='pit',\n",
    "    aux=aux_period\n",
    ")\n",
    "#rch.write()\n",
    "print(pv,min_rate,max_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a312ed-0185-4317-92d8-c71545bdedd3",
   "metadata": {},
   "source": [
    "# A water storage dam\n",
    "We will use a head dependent flux boundary condition, more specifically, the river package, to implicitly simulate the development of a water storage facility during the dewatering and mining phases. It is expected that this facility will remain operational in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d4e50-831f-43d6-894e-4e3a8d63d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam = os.path.join(gis_f,\"dam.shp\")\n",
    "dam_nodes = get_bnodes(dam)\n",
    "dam_nodes\n",
    "tops = mg.top[dam_nodes.astype('int')]\n",
    "max = np.max(tops)+0.1 # we will use this as the water level assigned to the river package\n",
    "cond = 160*160*0.01 # 160 m square cells and assume K of 0.1 and L of 0.1\n",
    "\n",
    "riv1_pdata = [((lay,node),max,cond,mg.top[node],\"dam\") for node in dam_nodes] #stage conduct, riv_bot\n",
    "riv1_period={}\n",
    "riv1_period[7]=riv1_pdata # making this one start 6 months before mining\n",
    "riv1 = flopy.mf6.ModflowGwfriv(gwf,boundnames=True,save_flows=True, maxbound=len(riv1_pdata),\\\n",
    "                               stress_period_data=riv1_period,pname='riv1',\n",
    "                               filename=\"{}_1.riv\".format(model_name),)\n",
    "# Setup obs arrays for drn\n",
    "obs9_recarray = {\n",
    "    \"riv1_dam_obs.csv\": [\n",
    "        (\"dam\", \"RIV\", \"dam\")]\n",
    "}\n",
    "riv1.obs.initialize(\n",
    "    filename=\"{}_1.riv.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs9_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f092a3-142a-4903-9e6a-8cca4f5bd775",
   "metadata": {},
   "source": [
    "# Setup MAW boundaries\n",
    "The current project plan calls for dewatering in the first year prior to the commencement of mining. After that wells located inside the pit will be destroyed so the need to be turned off in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fda3e-fa74-4c00-95e2-3a1cd1fb002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_gdf = gpd.read_file(wels)\n",
    "wel_gdf['node'] = well_nodes\n",
    "rad = 0.3\n",
    "condeqn = \"THEIM\"\n",
    "pakdata = []\n",
    "condata = []\n",
    "for i in range(len(wel_gdf)):\n",
    "    welnum = i\n",
    "    wel = wel_gdf.loc[i]\n",
    "    bottom = wel[\"Z\"] - wel[\"Bore Depth\"]\n",
    "    count = 0\n",
    "    node = wel[\"node\"]\n",
    "    start = mg.top[node]\n",
    "    name = wel[\"Bore\"]\n",
    "    for lay in range(nlay):\n",
    "        if mg.botm[lay][node]>bottom:\n",
    "            entry2 = (welnum,count,(lay,node),1,1,1,1)\n",
    "            condata.append(entry2)\n",
    "            count+=1\n",
    "    entry = (welnum,rad,bottom,start,condeqn,count,name)\n",
    "    pakdata.append(entry)\n",
    "# Then finally we also need period data\n",
    "maw_pdata={}\n",
    "pdata = []\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    welnum = i\n",
    "    r = -wel['Dewateri_2']\n",
    "    d = wel[\"Z\"] - wel[\"Pump Depth\"]\n",
    "    l = 1.0\n",
    "    settings = [[welnum,\"status\",\"active\"],[welnum,\"rate\",r],[welnum,\"rate_scaling\",d,l]]\n",
    "    pdata = [*pdata,*settings]\n",
    "maw_pdata[3] = pdata # all wells kick off 9 months prior to mining for this specific scenario\n",
    "# mining in South Pit starts in stress period 13 where wells 06, 23, 15 turn off\n",
    "pdata = []\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    name = wel[\"Bore\"]\n",
    "    welnum = i\n",
    "    r = -wel['Dewateri_2']\n",
    "    d = wel[\"Z\"] - wel[\"Pump Depth\"]\n",
    "    l = 1.0\n",
    "    if name in [\"MRBH06\",\"MRBH023\",\"MRBH015\"]:\n",
    "        settings = [[welnum,\"status\",\"inactive\"]]\n",
    "    else:\n",
    "       settings = [[welnum,\"status\",\"active\"],[welnum,\"rate\",r],[welnum,\"rate_scaling\",d,l]] \n",
    "    pdata = [*pdata,*settings]\n",
    "maw_pdata[12] = pdata\n",
    "# mining in the North pit starts in stress period 61 where well 16 also turns off\n",
    "pdata = []\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    name = wel[\"Bore\"]\n",
    "    welnum = i\n",
    "    r = -wel['Dewateri_2']\n",
    "    d = wel[\"Z\"] - wel[\"Pump Depth\"]\n",
    "    l = 1.0\n",
    "    if name in [\"MRBH016\",\"MRBH06\",\"MRBH023\",\"MRBH015\"]:\n",
    "        settings = [[welnum,\"status\",\"inactive\"]]\n",
    "    else:\n",
    "       settings = [[welnum,\"status\",\"active\"],[welnum,\"rate\",r],[welnum,\"rate_scaling\",d,l]] \n",
    "    pdata = [*pdata,*settings]\n",
    "maw_pdata[60] = pdata\n",
    "# Then we need all wells inactive from year 10 which is stress peiod 121\n",
    "pdata = [[i,\"status\",\"inactive\"] for i in range(len(wel_gdf))]\n",
    "maw_pdata[120] = pdata\n",
    "\n",
    "maw1 = flopy.mf6.ModflowGwfmaw(gwf,boundnames=True,save_flows=True,no_well_storage=True,\n",
    "                               shutdown_kappa=0.01,\n",
    "                               mfrcsv_filerecord=\"maw_reduce.csv\",\n",
    "                               nmawwells=len(well_nodes),\n",
    "                               packagedata= pakdata, connectiondata= condata , \n",
    "                               perioddata = maw_pdata, filename=\"{}_1.maw\".format(model_name))\n",
    "\n",
    "# Setup obs arrays for drn\n",
    "ls =[]\n",
    "for i in range(len(wel_gdf)):\n",
    "    wel = wel_gdf.loc[i]\n",
    "    name = wel[\"Bore\"]\n",
    "    ls.append((name,'maw',name))\n",
    "\n",
    "obs10_recarray = {\n",
    "    \"maw_obs.csv\": ls\n",
    "}\n",
    "maw1.obs.initialize(\n",
    "    filename=\"{}_1.maw.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs10_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df44d4-0466-4694-9e9c-adb8356e5b53",
   "metadata": {},
   "source": [
    "# ET package\n",
    "The same approach to recharge is used for ET. Note we are using the array version of the ET package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c40b26-ba65-4c03-99c8-e28cb72bfdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet = 1600 # mm/yr\n",
    "max_rate = pet/365/1000\n",
    "# assume our min rate is 50% less\n",
    "min_rate = 0.5*max_rate\n",
    "# our preferred value which is central to log of min and max\n",
    "pv =  10**(np.log10(min_rate)+((np.log10(max_rate)-np.log10(min_rate))/2)) \n",
    "\n",
    "ext_depth = 1.0 #meters\n",
    "et_rate_array = np.ones_like(mg.top)*pv\n",
    "et_depth_array = np.ones_like(mg.top)*ext_depth\n",
    "et_period = {}\n",
    "evt = flopy.mf6.ModflowGwfevta(\n",
    "    gwf,\n",
    "    readasarrays=True,\n",
    "    fixed_cell=False,\n",
    "    surface = mg.top,\n",
    "    rate = et_rate_array,\n",
    "    depth = et_depth_array,\n",
    "    filename=\"{}.evt\".format(model_name),\n",
    "    pname=\"evt\")\n",
    "print(pv,min_rate,max_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305ce24-73c8-4726-8b5c-e687087cdaf0",
   "metadata": {},
   "source": [
    "# Initial Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f01bb0-1cff-42db-820d-bd8521ee767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hdata from before\n",
    "ihd_array=np.ones_like(mg.botm)\n",
    "ihd_array[:] = mg.top-5\n",
    "last_ssheads = np.loadtxt(\"iheads_array.txt\")\n",
    "ihd_array[:]=last_ssheads\n",
    "\n",
    "ic = flopy.mf6.ModflowGwfic(\n",
    "    gwf, pname=\"ic\", strt=ihd_array, filename=\"{}.ic\".format(model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff245b3-b0c3-43b5-91ea-b3aebd0c8a9b",
   "metadata": {},
   "source": [
    "# Output control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb29d23-6387-4962-ae9b-c9ed93683816",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(range(1,205)) # this range represents the monthly stress periods before recovery\n",
    "hs_keys = [0,*_] # SSkey = 0, then all monthly SP\n",
    "\n",
    "h_rec = {key:[(\"HEAD\",\"LAST\")] for key in hs_keys}\n",
    "h_rec[205] = [(\"HEAD\",\"FREQUENCY\",12)] # the last period which is a 100 year recovery\n",
    "\n",
    "# combined head plus budget for zonebudget run\n",
    "zbud_rec = {key:[(\"BUDGET\",\"LAST\"),(\"HEAD\",\"LAST\")] for key in hs_keys}\n",
    "zbud_rec[205] = [(\"BUDGET\",\"FREQUENCY\",12),(\"HEAD\",\"FREQUENCY\",12)]\n",
    "\n",
    "#for budget printing to list file\n",
    "b_rec = {key:[(\"BUDGET\",\"LAST\")] for key in hs_keys}\n",
    "b_rec[205] = [(\"BUDGET\",\"FREQUENCY\",12)]\n",
    "\n",
    "\n",
    "oc = flopy.mf6.ModflowGwfoc(\n",
    "    gwf,\n",
    "    pname=\"oc\",\n",
    "    budget_filerecord=\"{}.cbb\".format(model_name),\n",
    "    head_filerecord=\"{}.hds\".format(model_name),\n",
    "    headprintrecord=[(\"COLUMNS\", 10, \"WIDTH\", 15, \"DIGITS\", 6, \"GENERAL\")],\n",
    "    saverecord=zbud_rec,\n",
    "    printrecord=b_rec,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e48d7-fa99-40de-ba56-c9db21a63977",
   "metadata": {},
   "source": [
    "# Hydraulic heads at locations\n",
    "We have a shapefile of locations where we would like to observe simulated hydraulic heads. The shapefile already has the node numbers of the grid as an attribute for each location in addition to the layer number of the known well screen. Some of these locations are water supply bores for neighbouring villages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1baa5-60e4-467d-a3c0-6dc1c4598c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf1 = gpd.read_file(os.path.join(gis_f,'monitoring.shp'))\n",
    "columns = [\"Name\",\"nodenumber\",\"layer\"]\n",
    "df1 = gdf1[columns]\n",
    "df1 = df1[df1[\"layer\"]==0].copy()\n",
    "df1.index=range(len(df1))\n",
    "temp2 = [(df1['Name'][i],\"HEAD\",(int(df1['layer'][i]),df1['nodenumber'][i]-1)) for i in range(len(df1))]\n",
    "\n",
    "\n",
    "obs_recarray = {}\n",
    "obs_recarray['head_obs.csv'] = temp2\n",
    "obs_package = flopy.mf6.ModflowUtlobs(\n",
    "    gwf,\n",
    "    pname=\"head_obs\",\n",
    "    filename=\"{}.obs\".format(model_name),\n",
    "    digits=10,\n",
    "    print_input=True,\n",
    "    continuous=obs_recarray,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7cda4-9f3e-4c93-a9a0-4dec14651f75",
   "metadata": {},
   "source": [
    "# Solute transport\n",
    "It is expected that the backfill and the waste rock could leach chemicals that may become a problem once the regional gradient is established post-mining operation. For this preliminary assessment we will set up a basic solute transport model. That we can explore with more detail through our Monte-Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3319bb-eecb-499f-8108-8155210b3f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel_name='trans'\n",
    "\n",
    "# the transport model basic object\n",
    "gwt = flopy.mf6.ModflowGwt(sim,modelname=tmodel_name)\n",
    "\n",
    "imst = flopy.mf6.ModflowIms(sim, complexity='MODERATE', csv_inner_output_filerecord='inner_t.csv',\\\n",
    "                           csv_outer_output_filerecord='outer_t.csv', outer_maximum=500, inner_maximum=500,\n",
    "                          outer_dvclose=0.1, inner_dvclose=0.01,filename = \"{}.ims\".format(tmodel_name))\n",
    "sim.register_ims_package(imst, [gwt.name])\n",
    "\n",
    "# setup the transport disv package\n",
    "disvt = flopy.mf6.ModflowGwtdisv(gwt,angrot=0,length_units=\"METERS\", **gridprops_vg)\n",
    "disvt.botm = new_botms\n",
    "disvt.top = top_data\n",
    "\n",
    "# we will need to add this to our storage creator script\n",
    "# set porosity at 1% more than yield\n",
    "por = flopy.mf6.ModflowGwtmst(gwt, porosity=0.1)\n",
    "\n",
    "# simple zero concentration starting condition\n",
    "ict = flopy.mf6.ModflowGwtic(gwt, strt=0.0)\n",
    "\n",
    "# basic advection package\n",
    "adv = flopy.mf6.ModflowGwtadv(gwt, scheme=\"UPSTREAM\")\n",
    "\n",
    "# dispersion package with all bells\n",
    "dsp = flopy.mf6.ModflowGwtdsp(gwt, xt3d_off=True, \n",
    "                        diffc=1.4E-04, #m2/d approximate diffusivity of salt in water\n",
    "                        alh=30.0, # longitudinal horizontal\n",
    "                        alv=15.0, # longitudinal vertical\n",
    "                        ath1=6.0, # transverse horizontal 1\n",
    "                        ath2=6.0, # transverse horizontal 2\n",
    "                        atv=3.0) #transverse horizontal 3\n",
    "\n",
    "# going to add in concentration for tailings using spit_nodes\n",
    "cnc_data = {}\n",
    "pdata = []\n",
    "for lay in range(0,nlay): # note this specific scenario considers concentration in layer 1.\n",
    "    for node in spit_nodes.astype(\"int\"):\n",
    "        pdata.append(((lay,node),'leachate','tailings'))\n",
    "cnc_data[stop_mine]=pdata # note this will apply until end of simulation\n",
    "cnc = flopy.mf6.ModflowGwtcnc(gwt,boundnames=True,save_flows=True,maxbound=len(pdata) ,\n",
    "                              stress_period_data = cnc_data,filename=\"{}_1.cnc\".format(tmodel_name),\n",
    "                              pname = 'cnc_1')\n",
    "# initialise time series for concentration change\n",
    "# make the tsdata\n",
    "stime = model_time[stop_mine-1] # model run time in days at stop_mine\n",
    "sptime = model_time[-1] # model run time in days at end of model run\n",
    "# assume linear decrease in concentration down to 10% over 50 years\n",
    "# 50 years in days is approximatley 50*365.25\n",
    "ts_data = [(1.0,100.0),(stime,100.0),(stime+(25*365.25),10.0),(sptime,10.0)] # note you must have this start at t=1.0 and end at the end of the model run\n",
    "# initialize first time series\n",
    "cnc.ts.initialize(\n",
    "    filename=\"cnc.ts\",\n",
    "    timeseries=ts_data,\n",
    "    time_series_namerecord=['leachate'],\n",
    "    interpolation_methodrecord=[\"linear\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Need to add this to stop ET taking conc\n",
    "spc_dict = {}\n",
    "spc_dict[0]=0.0 # no conc in first stress period\n",
    "spc_dict[1]=0.0\n",
    "spc1 = flopy.mf6.ModflowUtlspca(gwt,concentration=spc_dict,\n",
    "                         pname='spca1',\n",
    "                         filename=\"{}_1spc.spca\".format(tmodel_name))\n",
    "spc2 = flopy.mf6.ModflowUtlspca(gwt,concentration=spc_dict,\n",
    "                         pname='spca2',\n",
    "                         filename=\"{}_2spc.spca\".format(tmodel_name))\n",
    "\n",
    "# use a stress period array file for ssm recharge combination\n",
    "ssm = flopy.mf6.ModflowGwtssm(gwt,fileinput=['rch','trans_1spc.spca']) # note this is here as a dummy because of a bug\n",
    "ssm.fileinput.append_list_as_record(['evt','trans_2spc.spca', 'MIXED'])\n",
    "\n",
    "\n",
    "test = list(range(1,205)) # this range represents the monthly stress periods before recovery\n",
    "hs_keys = [0,*test] # SSkey = 0, then all monthly SP\n",
    "h_rec = {key:[(\"CONCENTRATION\",\"LAST\")] for key in hs_keys}\n",
    "h_rec[205] = [(\"CONCENTRATION\",\"FREQUENCY\",12)]\n",
    "#repeat for budget printing\n",
    "b_rec = {key:[(\"BUDGET\",\"LAST\")] for key in hs_keys}\n",
    "b_rec[205] = [(\"BUDGET\",\"FREQUENCY\",12)]\n",
    "oct = flopy.mf6.ModflowGwtoc(\n",
    "    gwt,\n",
    "    concentration_filerecord=f\"{gwt.name}.ucn\",\n",
    "    concentrationprintrecord=[(\"COLUMNS\", 10, \"WIDTH\", 15, \"DIGITS\", 6, \"GENERAL\")],\n",
    "    saverecord=h_rec,\n",
    "    printrecord=b_rec,\n",
    ")\n",
    "\n",
    "# add the exchange package\n",
    "exg=flopy.mf6.ModflowGwfgwt(\n",
    "        sim, exgtype=\"GWF6-GWT6\", exgmnamea=gwf.name, exgmnameb=gwt.name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d07e3-1375-45c6-b00d-a7a96678c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7475eee-e988-440b-8ec2-69dfe8815bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_simulation(silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e944d1-cce3-41eb-8b74-be6ad4443dd5",
   "metadata": {},
   "source": [
    "# Save the SS heads for use when running the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940f2b9-f283-4464-aa7b-08e4ba96ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headfile = os.path.join(model_f,\"{}.hds\".format(model_name))\n",
    "hds = flopy.utils.binaryfile.HeadFile(headfile)\n",
    "h = hds.get_data((0,0))\n",
    "np.savetxt(\"iheads_array.txt\",h[0])\n",
    "print(np.max(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c496498-185c-4163-96ed-bd7f3d3fef95",
   "metadata": {},
   "source": [
    "# The budget summary at end of mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a7ce2-9cf5-4ccf-ae18-104df116b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at budget summary\n",
    "lst = flopy.utils.Mf6ListBudget(os.path.join(model_f,\"flow.lst\"))\n",
    "start_datetime='31-12-2023'\n",
    "df_flux, df_vol = lst.get_dataframes()\n",
    "\n",
    "# use the spnum variable to select a specific stress period\n",
    "spnum = 121\n",
    "groups = df_flux.groupby(lambda x: x.split(\"_\")[-1], axis=1).groups\n",
    "df_flux_in = df_flux.loc[:, groups[\"IN\"]]\n",
    "df_flux_in.columns = df_flux_in.columns.map(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "df_flux_out = df_flux.loc[:, groups[\"OUT\"]]\n",
    "df_flux_out.columns = df_flux_out.columns.map(lambda x: x.split(\"_\")[0])\n",
    "\n",
    "df_flux_delta = df_flux_in - df_flux_out\n",
    "df_flux_delta = df_flux_delta*0.001\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "df_flux_delta = df_flux_delta.drop(columns=[\"RCHA\",\"EVTA\"]) # note these are huge in comparison so we are dropping them for now.\n",
    "df_flux_delta.iloc[spnum, :].plot(kind=\"bar\", grid=True,ax=ax)\n",
    "plt.ylabel(\"ML/d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237d18f-6402-44e6-b56e-e670c53b13a4",
   "metadata": {},
   "source": [
    "# Conservative solute plume 50 years post mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd69b2-7ded-4ff0-a873-2ab061808e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "concfile = os.path.join(model_f,\"{}.ucn\".format(tmodel_name))\n",
    "conc = flopy.utils.binaryfile.HeadFile(concfile,text=\"conc\")\n",
    "c = conc.get_data((1199,205)) # 50 years post mine closure\n",
    "max = np.max(c)\n",
    "min = np.min(c)\n",
    "print(min,max)\n",
    "mg=gwf.modelgrid\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "mapview = flopy.plot.PlotMapView(modelgrid=mg)   \n",
    "pc = mapview.plot_array(c, cmap='viridis')\n",
    "colorbar = plt.colorbar(pc, aspect=30)\n",
    "#contour_set = mapview.contour_array(h, levels=levels, colors='w',linewidths = 0.75)\n",
    "#ax.clabel(contour_set, fmt='%.1f', colors='w', fontsize=8)\n",
    "ax.set_title('% Source concentration Layer 1')\n",
    "#ax.set_xlim(extents[0],extents[2])\n",
    "#ax.set_ylim(extents[1],extents[3])\n",
    "ax.set_xlabel('Eastings')\n",
    "ax.set_ylabel('Northings')\n",
    "ax.ticklabel_format(style='plain') #  gets rid of the exponent offsets on the axis\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f7a5a-80bd-4f83-81a9-21108fafde13",
   "metadata": {},
   "source": [
    "# Zonebudget for flux from each geological unit into the South Pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b2625-481a-41aa-b680-5e070b680354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a zone array\n",
    "zarr = np.ones(mg.shape,dtype=int)\n",
    "# first make all our layers seperate zones\n",
    "for i in range(1,nlay+1):\n",
    "    zarr[i-1]*=i\n",
    "\n",
    "# recall that we already know the nodes for South Pit from the drn5 package\n",
    "# here I am getting the layer,node tuples that were assigned in the package\n",
    "_ = drn5.stress_period_data.data # this is the stress period dictionary\n",
    "tups = [_[key][x][0] for key in _.keys() for x in range(len(_[key]))] # gets me all the tuples\n",
    "uq_tups = list(set(tups)) # leverage set to easily get unique tuples, so dumping repeats\n",
    "spitnodes_lay1 = [x[1] for x in uq_tups if x[0]==0] # gets me the nodes used in layer 1\n",
    "spitnodes_lay2 = [x[1] for x in uq_tups if x[0]==1] # gets me the nodes used in layer 2\n",
    "spitnodes_lay3 = [x[1] for x in uq_tups if x[0]==2] # gets me the nodes used in layer 3\n",
    "\n",
    "# Now change the zarr to get spitnodes as a seperate zone\n",
    "zarr[0,spitnodes_lay1]=4\n",
    "zarr[1,spitnodes_lay2]=4\n",
    "zarr[2,spitnodes_lay3]=4\n",
    "\n",
    "# Step2: Create zbud object\n",
    "zbud = gwf.output.zonebudget(zarr)\n",
    "\n",
    "# Step3: Zonebudget Object settings\n",
    "# Change workspace\n",
    "zbud.change_model_ws(model_f) # make sure it runs in the model folder\n",
    "\n",
    "# Step4: Make input files\n",
    "zbud.write_input()\n",
    "\n",
    "# Step5: Run Zbud\n",
    "zbud.run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008a35c-4ff3-460a-8bc8-8d140f976483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step6: Get ZoneBudget Output\n",
    "df = zbud.get_dataframes(net=True,zones='ZONE_4')\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc43c9d-395a-46f2-9929-1f20493bffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step7: Plot the net inflow over time from each layer\n",
    "# get flows from layer 1\n",
    "cols = ['Saprolite','Transition','Basement']\n",
    "plot_df = pd.DataFrame(columns=cols)\n",
    "for i in range(1,nlay+1):\n",
    "    tdf = df[df['name']==f'ZONE_{i}']\n",
    "    plot_df[cols[i-1]]=tdf['ZONE_4'].to_list()\n",
    "start=pd.to_datetime(\"2023-12-31\")\n",
    "times = [start+pd.Timedelta(days=x) for x in tdf['totim']]\n",
    "plot_df.index=times\n",
    "plot_df[plot_df<-2000.0]=np.NaN\n",
    "for col in plot_df.columns:\n",
    "    if plot_df[col].isna().any():\n",
    "        plot_df[col].interpolate(inplace=True)\n",
    "plot_df['Total'] = plot_df.sum(axis=1)    \n",
    "ax = plot_df.plot(ylabel='Flux kL/d', xlabel='Date', title='South Pit Flux (+ve = flow in)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723df49-3c5f-4d0e-a290-c058a21d2dd1",
   "metadata": {},
   "source": [
    "# Setting up packages with external arrays for PEST/PESTPP/Pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d39b2e-c7ae-48e3-9693-8cc5ed234ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ws = os.path.join(ws8,\"model_ext\")\n",
    "if os.path.exists(new_ws):\n",
    "    shutil.rmtree(new_ws)\n",
    "    os.mkdir(new_ws)\n",
    "\n",
    "sim.set_sim_path(new_ws)\n",
    "plist = [ghb1,ghb2,drn1,drn2,drn3,drn4,npf,rch,evt] # only theses package will be set to have external arrays\n",
    "for pak in plist:\n",
    "    pak.set_all_data_external(external_data_folder=\"extfiles\")\n",
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec20a8-0009-4340-964e-9c91df64c565",
   "metadata": {},
   "source": [
    "# Thats all folks\n",
    "Hopefully at this stage you are comfortable enough with developing a model using Flopy. If there is time available at the end of this session we will look through the model report for this specific project so you also get an idea how PEST/PESTPP was used to explore the prior probability distributions of the model parameters thereby providing some preliminary indication of the projects impacts and infrastructure requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794cd1dd-6bef-485d-83d8-4e779145ffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
